Job_Index,Job_Title,Company_Name,Job_Location,Tasks,Skills,Job_Search_Term
1,Senior Consultant - Consulting - Data Management & Governance,EY (Ernst & Young AG),Zurich,"You will work on Data Governance and Data Management topics on a project basis, for and in collaboration with customers throughout Switzerland and internationally. | You will work for interesting national and international organizations in various domains such as Supply Chain, Finance, Risk, etc. and across various sectors like Life Sciences, Consumer Products & Retail, etc. | You will learn through knowledge sharing, trainings and on the job experiences. | You will contribute to develop new propositions and innovative solutions that are responsive to market needs. | You will support in growing the Data Strategy, Management and Governance team.","Hold a master's degree with a minimum of three years' experience in Data Management, including Data Strategy, Data Governance, Master Data Management, Metadata Management, and Data Quality. | Proven track record in implementing data governance frameworks (e.g., DAMA, DCAM, CMMI, COBIT) and performing maturity assessments. | Proficiency with Master Data Management Software (e.g., SAP MDG, Reltio, SAS) and data governance tools (e.g., Collibra, Informatica). | Experience with cloud platforms such as Azure, AWS, Google Cloud is highly desirable. | Exhibit a flexible, proactive approach, with excellent team collaboration and communication skills. | Business fluency in both English and German is required. | A keen interest or background in AI and data analytics is advantageous.",Data Science
2,Data/BI Engineer 80-100% (m/w),Komax Group,6036 Dierikon,"Entwickeln einer neuen Datenplattform mit MS Fabric zusammen mit dem BI & Analytics Team | Aufnahme und Definition der Daten-Anforderungen gemeinsam mit den Fachbereichen | Übersetzung fachlicher Anforderungen in technische Konzepte und Lösungen | Definition und Pflege von Data Products und deren Beschreibung im Data Catalog | Etablierung und Weiterentwicklung von Standards für Data Governance, Data Security und Data Quality | Unterstützung und Support der Fachbereiche bei der Nutzung von Power BI | Anleitung und Enablement der Analytics-Spezialisten in den Fachbereichen | Zusammenarbeit mit Data Engineers zur Sicherstellung der Datenverfügbarkeit und -qualität im Data Lakehouse (Microsoft Fabric) | Visualisierung und Analyse von Daten zur Ableitung von Handlungsempfehlungen","Abgeschlossenes Studium in Wirtschaftsinformatik, Data Science, Statistik oder vergleichbare Qualifikation | Ausgeprägte analytische Fähigkeiten und Kommunikationsstärke | Erfahrung in der Arbeit mit modernen Datenplattformen und Data Governance Frameworks | Kenntnisse in Microsoft Fabric, Power BI, Azure oder vergleichbaren Technologien von Vorteil | Erfahrung in der Zusammenarbeit mit Fachbereichen und im Requirements Engineering | Verständnis für Datenqualität, Datenschutz und Informationssicherheit",Data Science
3,Praktikant/in Lage- und Nachrichtenzentrum mit Fokus in Data Science (m/w/d) - befristet für 6 - 12 Monate,Kanton St. Gallen,St.Gallen,"Konzeption und Aufbau von Data Pipelines (Erfassung bis Visualisierung) | Entwicklung interaktiver Reports | Optimierung unseres Daten-Ökosystems (Architektur, Performance & Usability) | Dokumentation der reibungslosen Betriebsübernahme","Studium mit Bezug zur Aufbereitung und Auswertung von Daten (z.B. Data Science, Data Analytics, Data Engineering, Wirtschaftsingenieurswesen mit Vertiefung Datenanalyse, usw.) | Oder anderweitige Aus- oder Weiterbildung mit starkem Interesse an der Arbeit im Sicherheitsbereich bzw. in den polizeilichen Tätigkeiten in Kombination mit ausgeprägtem technischem Verständnis | Idealerweise Kenntnisse von Workflowsoftware, Pipeline- und Analysetools sowie versierter Umgang mit Docker | Freude an der Verbesserung von Arbeitsabläufen | Hohe Eigenmotivation und Selbständigkeit",Data Science
4,Software Development Engineer,Bühler AG,Uzwil,"You develop, validate, and deploy predictive and prescriptive models in agile software projects (Python, KQL) | You create physics-informed models to fuse process knowledge with data-driven insights. | You are responsible for the development and life cycle of containerized Data Models to run on an Azure Cloud environment | You are responsible for constant code reviews and creation of tests | You enjoy continuous, pro-active collaboration with the project management and cloud platform department in interdisciplinary projects","BSc. or MSc. in Data Science, Software Engineering, Electrical/Control Engineering, Applied Mathematics, Statistics, or related field | Proficiency in programming languages (Python), machine learning, statistical analysis | English spoken and written (atleast B2) | Experience in agile working principles, DevOps, GIT | Strong problem-solving abilities and the capacity to think critically about data and identify relevant questions to ask",Data Science
5,Research Software Engineer,ETH Zürich,Zürich,"Master or PhD degree in computational sciences or related field such as physics, bioinformatics, computer science, etc.; | good understanding of the fundamentals of natural sciences, numerical methods and scientific programming; | mastery of Python and 2-3 other programming languages (e.g., C/C++, R, Julia, Rust) and knowledge of object-oriented programming and software design; | hands-on experience in full stack web development (back- and front-end) and corresponding web frameworks (e.g., FastAPI, Django); | experience in applying best practices in scientific programming (e.g., automated testing and version control) and container technology (e.g., Docker); | proficiency with the command line and the Linux compute environment. | Motivation letter; | CV; | Diplomas and work certificates; | Contact information of at least two references.","experience in application deployment, operation and maintenance on Kubernetes clusters, virtual machines or cloud environments; | hands-on experience with HPC clusters (e.g. Slurm), optimization and parallelization or GPU computing (e.g., Dask, ipyparallel) and with the usage of workflow managers (e.g., Snakemake, Nextflow, etc.).",Data Science
6,Machine Learning Engineer – Personalization & Recommendations (a),Consult & Pepper AG,Neuchâtel (Hybrid),"Application Layer Development
Design and build the foundation of Aktiia’s next-generation recommendation engine together with a cross-functional software team (~20 engineers). | Dynamic User Modeling
Develop evolving user profiles that adapt continuously as new data and interactions are integrated. | Insight Generation
Transform raw signals into clear, personalized, and engaging user-facing experiences. | Cross-Domain Adaptation
Leverage proven methods from recommendation-heavy domains (e.g. travel, streaming, commerce) and adapt them to digital health. | End-to-End Ownership
Drive projects from prototyping and experimentation through testing, deployment, and iteration in production. | Collaboration
Work closely with product, data science, and engineering teams to ensure solutions are robust, user-friendly, and aligned with business goals. | Pioneering Role
Help Aktiia apply recommender system principles in a new domain, shaping something that has not been built before.","Academic Background
PhD or MSc in Informatics, Mathematics, Physics, Biology,Data Science, Signal Processing or related field. | Professional Expertise
4+ years of experience building and deploying recommendation systems in production, with expertise in personalization, clustering, and recommendation logic.
Proven track record generating user-facing insights and iterating recommendation models at scale. Knowledge of reinforcement learning and its application to personalization and recommendation systems. | Technical Experience
Strong programming skills in Python with hands-on experience in modern ML/AI frameworks. Skilled in building, validating and deploying ML models. Familiar with data pipelines, cloud and best engineering practices. Experience with large language models (LLMs), including practical use of open-source models, RAG, embeddings, and fine-tuning. | Industry Fit
Preferred background in recommendation-driven industries such as travel, streaming, e-commerce, advertising or digital marketing. Ideally from start-ups or mid-sized companies with end-to-end system ownership. | Language Skills
English at highly proficient level is a must. French, German or Italian are advantageous. | Personality
Hands-on, execution-driven product builder with strong ownership, accountability, and customer focus. On top you are a strong team player!",Data Science
7,Supply Chain Analyst,Vorwerk International & Co. KmG,Wollerau,"Develop and visualize relevant supply chain KPIs to drive operational excellence | Create user-friendly dashboards and reports (especially in Qlik) | Identify risks, weaknesses, and improvement opportunities through data analysis | Analyze and enhance existing processes in close collaboration with SCM, logistics, and related areas | Support the standardization and digitalization of control processes | Analyze and optimize interfaces between countries, logistics hubs, other company entities, and 3PL partners | Contribute to the further development of planning and control systems (e.g., SAP IBP) | Prepare ad-hoc analyses and present data-driven recommendations","Completed degree in Business, SCM, Data Science, or a related field | Experience in KPI and BI environments with strong analytical skills | Excellent understanding of end-to-end supply chain processes | Knowledge of SAP IBP/S/4HANA and BI tools such as Qlik is a plus | Basic SQL skills for working with data sources and creating efficient analyses (e.g., for | Qlik dashboards) | Experience in process management (Lean, Six Sigma, BPMN desirable) | Structured and conceptual way of working, with strong presentation skills | High self-motivation and potential, with willingness to take on leadership responsibilities in the medium term",Data Science
8,Data & AI Lakehouse Engineer 80-100% m/w/d,Victorinox AG,Ibach-Schwyz,"Entwerfen, implementieren und optimieren der Fabric-Lakehouse-Architektur inkl. ELT-Pipelines und Capacity-Management | Entwickeln, betreuen und performance-tunen komplexer Power BI-Datenmodelle und -Berichte in enger Abstimmung mit Fachbereichen | AI-Readiness schaffen: Datenprodukte für Machine-Learning- und Gen-AI-Use-Cases vorbereiten und erste Prototypen realisieren basierend auf der Fabric Lakehouse Plattform | Know-how-Transfer und Coaching innerhalb der BI-Community, um Best Practices für Fabric und Power BI im Unternehmen zu verankern | Sicherstellen von Datenqualität, Security und Compliance sowie Automatisierung von CI/CD-Workflows","Abgeschlossenes Studium in Informatik, Data Science oder vergleichbare Qualifikation | Erfahrung im Bereich Data-/BI-Engineering auf dem Microsoft Stack, davon mindestens 2 Jahre mit Azure und/oder Microsoft Fabric | Sehr gute Kenntnisse in DAX, Power Query, SQL, SparkSQL, Phython | Erfahrung mit modernen Data-Engineering-Tools | Interesse an AI-Technologien und deren praktischer Anwendung | Sehr gute Deutsch (C1/C2) - und Englischkenntnisse (C1/B2) | Analytisches Denken, Eigeninitiative und Freude an der Zusammenarbeit mit Fachbereich",Data Science
9,Junior Quantitativer Analyst (w/m/d),Raiffeisen Schweiz,St. Gallen und/oder Zürich-Flughafen (The Circle),"Du entwickelst und überprüfst statistische Modelle zur Risikoquantifizierung – von Kreditrisiko über Markt- bis hin zu operationellem Risiko | Du analysierst Daten, bereitest sie auf und unterstützt bei der Erstellung von quantitativen Auswertungen | Du bringst deine Ergebnisse auf den Punkt – und kommunizierst sie klar und verständlich an interne und externe Stakeholder | Du arbeitest eng mit Teams innerhalb und ausserhalb der Abteilung und des Bereichs zusammen","Abgeschlossenes Masterstudium an einer Universität mit quantitativem Fokus (Mathematik, Physik, Statistik, Data Science oder Naturwissenschaften) | Mind. 2 Jahre Berufserfahrung im Finanzumfeld | Kenntnisse in Finanzmathematik, Wahrscheinlichkeitstheorie und Statistik - idealerweise mit Anwendung im Kreditrisikokontext | Programmierkenntnisse in R oder Python, Grundkenntnisse in SQL, LaTeX und Git sind ein Plus | Neugier, Eigeninitiative und Motivation dich in komplexe Themen einzuarbeiten und Verantwortung zu übernehmen | Sehr gute Deutschkenntnisse werden vorausgesetzt",Data Science
10,Teamleiter/in Data Engineering,Diartis AG,Lenzburg,"Personelle und fachliche Führung des Teams Data Engineering (3 Personen) | Strategische Weiterentwicklung der Services unseres Teams (Datenmigration und Reporting) inkl. Mitwirkung an bereichsübergreifenden Boards | Selbstverantwortliche Arbeits- und Ressourcenplanung in Absprache mit unseren Projektleitenden | Sicherstellen der Pflege von Anleitungen und Dokumentationen | Umsetzung von AdHoc- und SSRS-Reports für interne und externe Stakeholder | Planung, Konzipierung und Durchführung von Datenmigrationen mit Kunden und Weiterentwicklung der Migrationsroutinen | Beratung und Unterstützung deiner Firmenkollegen und -kolleginnen in Sachen Reporting und SQL","Du hast Führungserfahrung und bist gerne mit Menschen unterwegs | Studium in Data Science / Studium in Business Intelligence (Bachelor oder Master) oder eine vergleichbare Ausbildung | Fundierte Erfahrung in Reporting und Datenanalyse (SSRS, T-SQL, Power BI) | Buchhaltungskenntnisse von Vorteil | Erfahrung mit Datenmigrationen und Datenbank-Funktionalitäten (SQL Server, SSIS) | Analytisch-vernetztes Denken, lernfreudige und kommunikative Persönlichkeit sowie strukturierte Arbeitsmethodik | Verhandlungssicheres Deutsch, Französisch von Vorteil",Data Science
11,Einkäufer:in als Datenanalyst:in,Stadler Rail Schweiz AG,Bussnang,Analyse grosser Datenmengen aus der Beschaffung zur Identifikation von Trends und Mustern | Entwicklung innovativer Lösungen zur automatisierten Datenverarbeitung | Erstellung von Dashboards und Berichten zur Visualisierung von Ergebnissen | Unterstützung bei der Datenbereinigung und -aufbereitung | Unterstützung des Einkaufs bei strategischen Entscheidungen durch datengestützte Reports und Prognosen | Entwicklung von Materialkalkulationsmodellen unter Einbezug von Einkaufsinfosätzen,"Abgeschlossenes Studium in Betriebswirtschaft, Data Science, Wirtschaftsinformatik oder einem vergleichbaren Bereich | Fundierte Berufserfahrungen im Einkauf | Erfahrung in der Analyse komplexer Beschaffungsprozesse und Materialkalkulationen | Kenntnisse in Analyse-Tools wie SQL, Excel, Power BI, R oder Python | Erfahrung mit SAP S/4HANA, insbesondere im Modul MM und Einkaufsinfosätzen | Ausgeprägtes analytisches Denkvermögen und hohe Zahlenaffinität | Kommunikationsstärke und die Fähigkeit, komplexe Sachverhalte verständlich zu vermitteln",Data Science
12,Business Analyst Finanzsysteme (m/w/d),Naturenergie Hochrhein AG,Laufenburg,"Perspektiven: Wachse mit uns – beruflich und persönlich. | Sinnhaftigkeit: Gestalte die Energiewende nachhaltig und wirksam. | Menschlichkeit: Erlebe ein vertrauensvolles Umfeld und echten Teamgeist. | Aktive Mitgestaltung der Weiterentwicklung unserer buchhalterischen Datenlandschaft und IT-Systeme im Hauptbuch | Gemeinsame Weiterentwicklung der zentralen Datenstrukturen (z. B. Sachkontenrahmen, Buchungskreise, automatisierte Buchungen) mit Kollegen | Beitrag zur Sicherstellung der Datenqualität und Steuerung buchhalterisch relevanter Datenflüsse | Unterstützung bei der Digitalisierung und Automatisierung von Finanzprozessen | Förderung der Zusammenarbeit zwischen Rechnungswesen, IT und BI in bereichsübergreifenden Projekten | Mitwirkung an Projekten, digitalen Lösungen und Dateninitiativen | Mithilfe bei der Etablierung moderner Reporting- und Analysemethoden im Finanzbereich | Abgeschlossenes Studium der Wirtschaftsinformatik, Betriebswirtschaft mit IT-Schwerpunkt, Data Science, (Wirtschafts-)Mathematik oder eine vergleichbare Qualifikation | Erste Erfahrung im Umgang mit ERP-Systemen (idealerweise SAP FI) und Interesse an der Arbeit an Finanzdaten und -prozessen | Freude am Umgang mit Daten sowie idealerweise Berührungspunkte mit Tools wie Excel, Power BI oder SQL | Interesse an buchhalterischen Abläufen sowie die Bereitschaft, sich in Themen wie Buchhaltungsprozesse und Datenflüsse einzuarbeiten | Strukturierte, analytische Denkweise und Begeisterung für Digitalisierung und Weiterentwicklung | Teamgeist, Kommunikationsstärke und Freude an der Zusammenarbeit mit unterschiedlichen Fachbereichen und der IT",no skills found on this job ad,Data Science
15,Senior Data Developer (all),BKW Energie AG,Bern,"You take ownership of developing and migrating data applications to ensure quality, reliability and resilience | Legacy applications are refactored by you into scalable, maintainable, and efficient solutions, using objected-oriented designs | You design robust architectures, data models, and pipelines that guarantee consistent analytics and reporting | Our modern toolchain with Snowflake, Azure DevOps, Kestra, and Python environments is configured and operationalized by you in a structured way | You support colleagues during the transition to new platforms and provide methodical guidance to strengthen best practices | Shared libraries and reusable components you build make project delivery more productive","A Bachelor's or Master's degree in Computer Science, Data Science or a related field forms the foundation of your expertise | You bring at least five years of experience in building large data applications and are well-versed in Python, SQL, cloud data platforms, with ML/AI practices a plus | With your advanced skills in Snowflake, Azure DevOps and Git, you can plan, control, and verify complex development processes | You have a solid understanding of financial or energy trading markets and risk metrics and can apply them reliably in data solutions | You are comfortable setting up semantic models and creating efficient dashboards and analytics with Looker, making insights precise and actionable | You bring an innovative and collaborative mindset, turning new ideas into reality from scratch",Data Science
16,Marketing Technology & Automation Specialist (m/w/d) 80-100%,Spotted by jobs.ch,Urdorf,"Verständnis der Marketing-Technologielandschaft und Integration von Marketing-Automatisierungsplattformen mit ERP- und CRM-Systemen | Fehlerbehebung und Lösung technischer Probleme im Zusammenhang mit Marketing- Automationsplattformen | Ausbau der Marketing Applikationslandschaft | Definition zukunftsfähiger Sales- & Marketingprozesse unter Berücksichtigung der IT-technischen Machbarkeit | Integration der Salesforce Marketing Cloud zur Sicherstellung des reibungslosen Datenflusses zwischen CRM-, CMS-, ERP-, PIM- und Marketing-Automatisierungssysteme | Umsetzung von Use-Cases zur Automatisierung von E-Marketing Aktivitäten | Steigerung der personalisierten Kundenansprache durch Implementierung personalisierter Kampagnen auf Basis von Kundendaten- und verhalten | Überwachung und Optimierung der Marketing-Kampagnen basierend auf Performance KPIs | Zusammenarbeit mit dem Produktmarketing zur effizienten Nutzung von Automatisierungsplattformen","Berufserfahrung: ca. 5 Jahre in relevanten Bereichen | Abschluss in Informatik, Statistik / Data Science, Wirtschaftsinformatik oder ähnlichem | IT-Kenntnisse in Automatisierungstools wie Salesforce, HubSpot, Marketo; CRM-Systeme (Salesforce, Microsoft Dynamics); CMS-Systeme (Typo3, WordPress) | Kenntnisse in HTML/CSS und Webtechnologien sowie praktische Kenntnisse von APIs für Integrationszwecke (präferiert) | Erfahrung mit Datenanalyse, A/B-Tests und Optimierung von Marketingkampagnen | Vertrautheit mit Analyseplattformen (z. B. Piwik Pro, Google Analytics) und Marketing-Reporting-Tools | Sonstige Kenntnisse: SEO / SEM & digitale Marketingkanäle | Weiterbildung im Bereich (e-)Marketing stark von Vorteil | Fliessende Deutsch und Englisch Kenntnisse",Data Science
18,HR-Controller/in,Kantonale Verwaltung Zürich,Zürich,"Fachhochschulabschluss in Accounting & Controlling, Betriebsökonomie, Data Science oder einer vergleichbaren Fachrichtung | Mehrjährige Erfahrung in einer ähnlichen Funktion sowie ausgewiesene Expertise im Daten- und Projektmanagement | Fundierte Kenntnisse im SAP Organisationsmanagement | Stilsicheres Deutsch in Wort und Schrift | Analytisches Denkvermögen, präzise Arbeitsweise und ausgeprägte Beratungskompetenz | Sicherer Umgang mit MS-Office, insbesondere Excel | Motivation für ein vielseitiges und verantwortungsvolles Tätigkeitsfeld","eine attraktive Position mit hoher Selbständigkeit und Gestaltungsspielraum | ein engagiertes Team, das Kollegialität und Humor lebt | Büroräumlichkeiten in Oerlikon (ab Frühling 2026 Umzug an die Ausstellungsstrasse in Zürich) und die Möglichkeit, auch in den eigenen vier Wänden zu arbeiten und noch einiges mehr...",Data Science
19,Data Scientist 80 - 100 % (w/m/d),Hamilton Bonaduz AG,Bonaduz,"Durchführung von AI-Studien und Umsetzung von Projekten über verschiedene Use Cases im Liquid Handling und in der Laborautomatisierung | Zusammenarbeit mit Product und Process Owners sowie Data und Domain Experts, um Anforderungen zu klären und Deliverables passgenau zuzuschneiden | Design von Machine Learning-Lösungen und zügiger Aufbau funktionsfähiger Prototypen. | Definition robuster Validierungs- und Benchmarking-Strategien | Unterstützung der Integration von Lösungen in Hamiltons Produkte, Services und Prozesse, indem Pilot Code zu deploybaren Software Artefacts gehärtet wird | Effektive Zusammenarbeit in einer Matrix Organisation und aktive Beiträge zum Knowledge Sharing innerhalb unserer AI Expert Group","Relevanter Hochschulabschluss (Master's/PhD) in Computer- oder Data Science, Mathematik, Ingenieurwesen oder einem verwandten Fachgebiet mit Fokus auf Machine Learning | Industriehintergrund und/oder Berufserfahrung in Software Development und Productisation. | Fundierte Kenntnisse in Data Structures und Data Modelling unter Nutzung fortgeschrittener Methoden in Machine Learning, Deep Learning, Reinforcement Learning, NLP und/oder Optimisation Techniques. | Erfahrung in der Anwendung von State-of-the-Art-Methoden auf Time-Series und/oder Text Data für industrielle Use Cases (z. B. Sensor Signal Processing, Condition Monitoring, Machine Calibration, Predictive Maintenance, Simulation-based Modelling). | Fähigkeit, sowohl selbstständig als auch in Cross-functional Projektteams zu arbeiten, mit einem Hands-on-Ansatz zur Problemlösung. | Ausgeprägte interdisziplinäre Kommunikations- und Collaboration Skills.",Data Science
20,Risk Manager (m/w/d),MF Group AG,St. Gallen,"das aktive Monitoring und die eigenständige Analyse von Dashboards und Reports zur Erkennung relevanter Entwicklungen sowie das fundierte Interpretieren von KPIs im Kontext des Risikomanagements | die Durchführung von Detailanalysen bei Auffälligkeiten, das Erkennen von Ursachen und Mustern sowie das Ableiten fundierter Handlungsempfehlungen | das Erstellen regelmässiger Reports und KPIs, um Risikotrends und -entwicklungen für das Management und weitere Stakeholder sichtbar zu machen | die Unterstützung bei der Pflege und Weiterentwicklung interner Richtlinien, Arbeitsanweisungen und Monitoring-Prozesse | die Mitarbeit an der Weiterentwicklung unserer Tools, zum Beispiel durch die Automatisierung wiederkehrender Aufgaben mit Excel, SQL oder Python","einem abgeschlossenen Studium in Wirtschaft, Finanzen, Mathematik, Informatik, Data Science oder einer vergleichbaren Fachrichtung | mindestens 1-3 Jahren Berufserfahrung im Risikomanagement, in der Datenanalyse, im Bereich Compliance, Fraud Prävention oder in einem ähnlichen Umfeld | sehr guten Kenntnissen in SQL und/oder Python zur Analyse und Weiterverarbeitung grosser Datenmengen | Erfahrung im Konzipieren und Erstellen von Dashboards, idealerweise mit gängigen Visualisierungstools wie Tableau oder Microsoft Power BI | fundierten Computerkenntnissen sowie exzellentem Umgang mit Microsoft Excel | sehr guten Englischkenntnissen; Italienischkenntnisse sind ein zusätzliches Plus",Data Science
25,Web Analytics & Insights Specialist (60-100%),Gonser AG,Hergiswil,"Fachliche Verantwortung, Betreuung und Weiterentwicklung des gesamten Webtrackings (insb. Google Analytics) in Zusammenarbeit mit unserer Webentwicklungsagentur | Analyse von Nutzerverhalten, Marketingmassnahmen und Customer Journeys | Planung, Durchführung und Auswertung von A/B-Tests zur Optimierung der Performance | Entwicklung und Erstellung von Reportings und interaktiven Dashboards für verschiedene Stakeholder | Aufbau von Analyse- und Monitoring-Prozessen inkl. KPI-Alerts | Identifikation von Trends und Optimierungspotentialen anhand von Wettbewerbs- und Marktanalysen | Kontinuierlicher Ausbau der Analyseinfrastruktur und Integration neuer Datenquellen | Mitgestaltung und Mitwirkung bei laufenden E-Commerce- und Webshopprojekten","Abgeschlossenes Studium in einem relevanten Bereich wie Wirtschaftsinformatik, BWL, Digital Marketing oder Data Science | Mindestens 2 Jahre Erfahrung in vergleichbaren Rollen wie Business Analyst, Web-Analyst oder im digitalen Marketing, idealerweise im E-Commerce Umfeld | Fundierte Erfahrung mit gängigen Analyse-Tools (Google Analytics, Power BI, Hotjar), Tracking Technologien (Google Tag Manager) und A/B-Testing Plattformen (z.B. Kameleoon) | Grundkenntnisse in HTML, CSS, JavaScript oder SQL von Vorteil | Ausgeprägtes analytisches und konzeptionelles Denken sowie technische Affinität | Verständnis für E-Commerce Mechanismen und Online-Kundenerlebnisse (z.B. Conversion Funnel, Einflussfaktoren auf Kaufentscheidungen) | Gute Deutschkenntnisse, Englisch von Vorteil | Kommunikationsstärke und Freude an interdisziplinärer Zusammenarbeit",Data Science
27,Data Architekt,Safeguard Global,"Thun, Berne, Schweiz","Architect the future: Plan, design, and manage end-to-end data architecture for space missions | Model with purpose:  Create data models and storage structures to handle vast, complex datasets | Integrate intelligence:  Connect satellite, ground station, and other mission-critical data sources | Own the lifecycle: Oversee the integrity and usability of data from acquisition to archival | Secure and comply:  Ensure high standards of data security, privacy, and compliance | Scale for the stars:  Build infrastructure ready to grow with increasing data volume and mission complexity | Always-on performance:  Design for high availability, reliability, and performance | Govern smartly:  Define access policies and safeguards to prevent misuse | Collaborate across galaxies:  Work closely with fellow system and enterprise architects to align with broader mission goals | A degree in Computer Science, Data Science, or a related field | Several years of experience in data architecture, engineering, or data lifecycle management | Hands-on experience in space technology and Dev(Sec)Ops environments | A proactive mindset and strong self-management skills | Ability to think systemically and solve complex, cross-functional challenges | Excellent communication and stakeholder management skills | EU and/or Swiss work permit, with no entries in public registers (required for security clearance) | Fluent English (spoken and written); Very good knowledge of German",Comprehensive Pension Fund: Secure your future with our robust pension plan. | Flexible Working Hours: Enjoy the freedom to balance work and life with our adaptable schedules. | 13th Month Salary: Receive an extra month's salary as a bonus for your hard work and dedication. | Generous Paternity Leave: Spend quality time with your new family member with our extended paternity leave. | Private Medical Insurance: Stay healthy and worry-free with our top-tier private medical coverage.,Data Science
28,Director Engineering & Technology,Brack.Alltron AG,Mägenwil,"Gesamtverantwortung für das Engineering-Department mit den Bereichen Software Engineering und IT Operations (>100 Mitarbeitende) | Direkte Führung der Head of Engineerings, Software Architekten und Head of IT Ops Weiterentwicklung und Implementierung unserer IT-Strategie und Enterprise-Architektur | Treffen von Technologie-Entscheidungen zu Cloud-Lösungen, KI-Anwendungen, der System-Landschaft sowie Microservice-Architekturen | Sicherstellung des stabilen Betriebs unserer technischen Plattformen | Budget- und Ressourcenverantwortung für den Engineering-Bereich | Enge Zusammenarbeit mit dem CIO bei der strategischen Führung der IT-Abteilung | Förderung einer Kultur der Exzellenz, Innovation und kontinuierlichen Verbesserung","Hochschulabschluss in Informatik oder einem verwandten Bereich (Mathematik, Physik, Data Science) oder gleichwertige Erfahrung | Mindestens 5 Jahre Erfahrung als CTO oder in einer vergleichbaren leitenden Funktion in einem grösseren Unternehmen | Fundierte Kenntnisse in Enterprise-Architekturen, Cloud-Technologien, Microservices und KI-Anwendungen | Praktische Erfahrung als Software Engineer und mit modernen Sprachen | Nachweisbare Erfahrung in der Führung crossfunktionaler Teams und agiler Softwareentwicklung | Strategisches und analytisches Denken mit hoher Ergebnisorientierung | Empathische und integrative Führungspersönlichkeit mit Gespür für die Weiterentwicklung von Mitarbeitenden | Fliessende Deutsch- und Englischkenntnisse",Data Science
29,MLOps Engineer 80 - 100% (w/m/d),LGT,Zürich,"Zusammenarbeit mit Data Scientists, Data Engineers und Architekten, um die Advanced Analytics & AI Plattform vor Ort und in der Azure-Cloud weiterzuentwickeln und zu skalieren | Zusammenarbeit mit Data Scientists, um Analytics/AI-Produkte zu produktisieren und an Endnutzer auszurollen | Sicherstellung der Sicherheit, Verfügbarkeit und Leistung der Advanced Analytics & AI Plattform | Implementierung und Verwaltung von Workflows für Continuous Integration (CI) und Continuous Delivery (CD) | Bereitstellung von Plattformunterstützung und Wartung | Bachelor-Abschluss oder höher in Informatik, Software Engineering, Systemadministration, Ingenieurwesen oder einem verwandten Fachgebiet oder eine gleichwertige Kombination aus Ausbildung und Erfahrung | 5+ Jahre Erfahrung als DevOps/MLOps Engineer in einer mittelgroßen bis großen IT-Organisation | 5+ Jahre Erfahrung in der Implementierung von Data-Science-Lösungen auf VPC, Azure oder AWS | Erfahrung mit GitLab, GitLab Pipelines und ArgoCD | Erfahrung mit Openshift, Kubernetes, S3 Storage und Python | Kenntnisse in IT-Sicherheitsarchitektur sind von Vorteil | Erfahrung in der Bereitstellung von LLM & ML Modellen | Flexible Arbeitsmodelle | Sabbaticals | Mindestens 25 Tage Jahresurlaub, abhängig vom Alter | Optionen für bezahlten Sonderurlaub | Mutterschafts- und Vaterschaftsurlaub, Möglichkeiten für zusätzlichen Elternurlaub | Subventionen für die Kindertagesstätte ""Villa Wirbelwind"" | Zusätzlicher Kinderbetreuungszuschuss für entgeltlich fremdbetreute Kinder bis 12 Jahre | Rabatte auf Bankprodukte und Dienstleistungen der LGT | Co-Investments bei der LGT | Rabatte auf Kranken- und Sachversicherungen | Pensionsplan mit individuellen Optionen | Verschiedene Initiativen zur Förderung der Mobilität/E-Mobilität | Anerkennung wichtiger Lebensereignisse | Wellness- und Gesundheitsprogramme | Bewegungs- und Sportprogramme | Wöchentlicher Obsttag und gesunde Mahlzeiten | Umkleideräume mit Duschen | Ruheräume | Interne Kurse | Externe Kurse an der Liechtenstein Academy | Unterstützung für externe Aus- und Weiterbildungen | Coaching- und Mentoring-Programme | Internationale Einsätze | Intrapreneurship-Programme","Ihr Team ist virtuell und hauptsächlich in Bendern, Liechtenstein, und Zürich, Schweiz, angesiedelt. | Sie arbeiten täglich mit Stakeholdern aus verschiedenen Standorten in APAC und Europa zusammen. | Hervorragende Kommunikationsfähigkeiten | Ausgeprägter Teamgeist | Wohlfühlen in einem schnelllebigen, agilen Umfeld",Data Science
30,Projektleiter/-in Daten & Analyse,Bundesamt für Rüstung armasuisse,Bern,"Anlaufstelle (SPOC) im Bereich Datenanalyse / Datenauswertungen für alle Stakeholder im Immobilienmanagement VBS | Bei der Durchführung von Auswertungen sowie bei der Optimierung von Datenanalysen beraten | Definition von Masterdaten, Datenmodellen, Datenkatalogen sowie Organisation von Datenströmen (Data Pipelines) und Datenschnittstellen sicherstellen | Umsetzungskonzepte und Projektaufträge für das Daten- und Informationsmanagement erstellen | Analyse-Infrastrukturen und -Werkzeugen konzipieren, realisieren und weiterentwickeln | Bei einer unternehmensweiten Datenarchitektur mitgestalten sowie bei der Weiterentwicklung des gesamten Daten- und Informationsmanagements mitarbeiten","Hochschulabschluss (Bachelor/Master) in Informatik, Wirtschaftsinformatik oder gleichwertige Ausbildung sowie Weiterbildung in Datenanalyse, Data Science oder ähnliches von Vorteil | Mehrjährige Erfahrung in der Auswertung von Daten, der Bearbeitung von Unternehmens- und öffentlichen Daten, der Erstellung von datengestützten Entscheidungsgrundlagen sowie der Aufbereitung von grafischen Informationen | Ausgewiesene Erfahrung in den Bereichen Big Data, Statistik & Machine Learning, Entwicklung von Datenprodukten, Datenschutz und Datensicherheit | Projektleitungserfahrung und Kenntnisse im Bereich IT-System und -Lösungsarchitekturen | Gute mündliche und schriftliche Kenntnisse einer zweiten Amtssprache setzen wir voraus. Mündliche Kenntnisse einer dritten Amtssprache sind von Vorteil",Data Science
31,"Lead AI & Product Engineer (B2B-Plattform, 100%)",HOGALOG AG,Winterthur,"Entwicklung KI-gestützter Produkte entlang strategischer Ziele, Nutzerbedürfnisse und technologischer Möglichkeiten. | Identifikation relevanter Use Cases und Konzeption konkreter Lösungsansätze mit Fokus auf Machine Learning und Künstlicher Intelligenz. | Umsetzung funktionaler Prototypen, um Ideen frühzeitig zu testen und gemeinsam mit Kunden und Stakeholdern zu validieren. | Bewertung neuer ML-/AI-Technologien hinsichtlich Machbarkeit, Reifegrad und geschäftlichem Nutzen sowie Ableitung fundierter Architektur- und Tooling-Entscheidungen. | Enge Zusammenarbeit mit unseren Entwickler:innen zur Überführung validierter Prototypen in robuste, skalierbare Produktlösungen. | Förderung datengetriebenen Denkens im Unternehmen und aktives Wirken als Impulsgeber:in für daten- und AI-getriebene Innovation.","Erfolgreich abgeschlossenes Hochschulstudium (mindestens BSc) in Informatik, Data Science, Machine Learning oder einem verwandten technischen Bereich. | Du hast bereits mindestens ein marktrelevantes Produkt oder Feature gebaut, das auf einem Large Language Model basiert (z. B. GPT, Claude, Mistral). Dabei hast du den gesamten Prozess mitgestaltet. | Du verfügst über fundierte Kenntnisse in der Evaluation von LLMs – z. B. durch eigene Metriken und Benchmarks. | Sehr gute Python-Kenntnisse, insbesondere im Kontext von LLM-Anwendungen (z. B. mit LangChain, LlamaIndex, transformers, OpenAI SDK, etc.). | Sicher im Umgang mit typischen Komponenten LLM-basierter Systeme wie Embedding Models, Vektordatenbanken (z. B. Pinecone, Weaviate, FAISS) und RAG-Architekturen. | Du verstehst die Konzepte hinter MLOps bzw. LLMOps (z. B. Reproduzierbarkeit, CI/CD für Prompts und Embeddings, Prompt-Versionierung, Logging von User-Feedback). | Sehr gute SQL-Kenntnisse sowie Fähigkeit, Logs und Nutzerinteraktionen auszuwerten und daraus ableitbare Verbesserungen zu identifizieren. | Erfahrung in der Zusammenarbeit mit Product Ownern, Softwareentwickler:innen und interdisziplinären Teams – du kannst AI-Technologie in greifbare Produkte übersetzen. | Du kannst AI-Konzepte klar und verständlich kommunizieren – sowohl innerhalb des Teams als auch gegenüber Stakeholdern ohne technischen Hintergrund.",Data Science
32,Product Lead Finance & HR,Brack.Alltron AG,Zürich und/oder Mägenwil,"Du führst fachlich durch fundiertes Verständnis der Unternehmensstrategie und tiefes Produktwissen in Deinen Bereichen – von Nutzerbedürfnissen über Markttrends bis hin zu technologischen und strategischen Anforderungen. | Du entwickelst unsere Systeme rund um die Bereiche Finance und HR mit Blick auf Wirtschaftlichkeit und Zukunftsfähigkeit, identifizierst Potenziale und Synergien und realisierst nachhaltige Lösungen gemeinsam mit Deinem funktionsübergreifenden Team | Du stellst den benutzerorientierten Produkterfolg sicher, indem du neue Funktionen effektiv kommunizierst und relevante Stakeholder aus Finance und HR sowie das Management aktiv einbindest. | Du nutzt deinen Methodenbaukasten, um Produkte unternehmerisch weiterzuentwickeln – mit einem klaren Fokus auf Effizienz, Nutzerbedürfnisse und technische Machbarkeit. | Du bist Teil eines agilen Teams und arbeitest hands-on aktiv an der Konzeption und Entwicklung nachhaltiger, skalierbarer technischer Lösungen für die Bereiche Finance und HR mit. | Du verantwortest die Produkt-Roadmap, deren Priorisierung sowie die kontinuierliche Evaluierung neuer Potenziale. | Du bist verantwortlich für die Analyse, Konzeption und Umsetzung neuer Features und Innovationen – von der Idee bis zum Going-Live. | Du treibst technologische Innovationen und Verbesserungen für diese Bereiche aktiv voran, hältst dich über Branchentrends und neue Technologien auf dem Laufenden und evaluierst deren Potenzial für unsere Plattform. | Du leitest die Auswahl und Einführung neuer Technologien her sowie etablierst Best Practices im Team.","Ein abgeschlossenes Studium der Wirtschaftsinformatik, Informatik, Data Science oder Betriebswirtschaftslehre mit dem Schwerpunkt Digitales Marketing oder vergleichbarer Abschluss. | Erste einschlägige Berufserfahrung im E-Commerce, idealerweise im digitalen Produktmanagement von Business Applications rund um Finance- und HR-Systeme | Fundiertes Verständnis agiler Softwareentwicklung und deren Methodiken wie Scrum und Kanban | Sehr gute Kommunikationsfähigkeiten, Überzeugungskraft und Durchsetzungsvermögen, Empathie | Sehr gutes Gespür für Benutzerbedürfnisse und deren Denkweisen und Absichten | Ausgeprägte analytische und konzeptionelle Fähigkeiten sowie hohe Problemlösungskompetenz und Kundenorientierung. | Gute Kenntnisse und sicherer Umgang mit gängigen KI- und LLM-Tools, einschliesslich Erfahrung im Prompt-Engineering, deren APIs und dem effizienten Einsatz von Embeddings. | Strukturiertes, selbständiges und kooperatives Arbeiten in einem interdisziplinären Team | Gutes Grundverständnis für zukunftsweisende Technologien, Systeme und Marktentwicklungen bei Finance- und HR-Systemen | Intrinsische Motivation, kontinuierlich relevante Optimierungspotenziale aufzuspüren und entsprechende Initiativen zu gestalten",Data Science
33,"Product Owner, Analytics Platform",MEDGATE,Allschwil,"Own and maintain the feature backlog for the analytics platform, balancing business needs, data insights, and platform consistency | Write clear, testable user stories with acceptance criteria aligned to technical requirements for data pipelines, data models, and BI dashboards | Ensure product integrity during new feature and data integration rollouts.","Define and champion the analytics platform vision, aligning [Medgate's] strategic goals with business data and reporting needs. | Collaborate with the Business Owner, TTL, data engineers, compliance teams, and other product team POs. | Proactively communicate delivery timelines, dependencies, and potential issues to stakeholders.",Data Science
34,Product Lead Logistik,Brack.Alltron AG,Mägenwil,"Du führst fachlich durch fundiertes Verständnis der Unternehmensstrategie und tiefes Produktwissen in Deinen Bereichen – von Nutzerbedürfnissen über Markttrends bis hin zu technologischen und strategischen Anforderungen. | Du entwickelst unsere Systeme rund um die Logistik mit Blick auf Wirtschaftlichkeit und Zukunftsfähigkeit, identifizierst Potenziale und Synergien und realisierst nachhaltige Lösungen gemeinsam mit Deinem funktionsübergreifenden Team | Du stellst den benutzerorientierten Produkterfolg sicher, indem du neue Funktionen effektiv kommunizierst und relevante Stakeholder wie die Logistikkollegen und das Management aktiv einbindest. | Du nutzt deinen Methodenbaukasten, um Produkte unternehmerisch weiterzuentwickeln – mit einem klaren Fokus auf Effizienz, Nutzerbedürfnisse und technische Machbarkeit. | Du bist Teil eines agilen Teams und arbeitest hands-on aktiv an der Konzeption und Entwicklung nachhaltiger, skalierbarer technischer Lösungen für den Bereich Logistik mit. | Du verantwortest die Produkt-Roadmap, deren Priorisierung sowie die kontinuierliche Evaluierung neuer Potenziale. | Du bist verantwortlich für die Analyse, Konzeption und Umsetzung neuer Features und Innovationen – von der Idee bis zum Going-Live. | Du treibst technologische Innovationen und Verbesserungen für diese Bereiche aktiv voran, hältst dich über Branchentrends und neue Technologien auf dem Laufenden und evaluierst deren Potenzial für unsere Plattform. | Du leitest die Auswahl und Einführung neuer Technologien her sowie etablierst Best Practices im Team.","Ein abgeschlossenes Studium der Wirtschaftsinformatik, Informatik, Data Science oder Betriebswirtschaftslehre mit dem Schwerpunkt Digitales Marketing oder vergleichbarer Abschluss. | Erste einschlägige Berufserfahrung im E-Commerce, idealerweise im digitalen Produktmanagement von Business Applications rund um Warehouse Systeme, Inbound und Outbound Logistik | Fundiertes Verständnis agiler Softwareentwicklung und deren Methodiken wie Scrum und Kanban | Sehr gute Kommunikationsfähigkeiten, Überzeugungskraft und Durchsetzungsvermögen, Empathie | Sehr gutes Gespür für Benutzerbedürfnisse und deren Denkweisen und Absichten | Ausgeprägte analytische und konzeptionelle Fähigkeiten sowie hohe Problemlösungskompetenz und Kundenorientierung. | Gute Kenntnisse und sicherer Umgang mit gängigen KI- und LLM-Tools, einschliesslich Erfahrung im Prompt-Engineering, deren APIs und dem effizienten Einsatz von Embeddings. | Strukturiertes, selbständiges und kooperatives Arbeiten in einem interdisziplinären Team | Gutes Grundverständnis für zukunftsweisende Technologien, Systeme und Marktentwicklungen bei Logistiksystemen und deren Logiken | Intrinsische Motivation, kontinuierlich relevante Optimierungspotenziale aufzuspüren und entsprechende Initiativen zu gestalten",Data Science
35,(Senior) Data Analyst Online Shop (w/m/d),Digitec Galaxus AG,Zürich,"Du analysierst das Nutzerverhalten und leitest daraus Hypothesen sowie Handlungsempfehlungen für die Produktentwicklung ab. | Gemeinsam mit Product Owner, Engineers und UX-Experten entwickelst du KPIs und stellst diese über benutzerfreundliche Reports zur Verfügung. | Du übernimmst die Konzeption und statistische Auswertung von Online-Experimenten und leitest daraus konkrete Handlungsempfehlungen ab. | Zusammen mit unseren Data Engineers und Data Scientists trägst du dazu bei, unsere Business-Intelligence-Infrastruktur weiterzuentwickeln und durch übergreifende Initiativen auszubauen. | Du übersetzt die Informationsbedürfnisse des Business in Tracking-Anforderungen und setzt diese gemeinsam mit den Entwicklern um.","Abgeschlossenes Studium im technischen oder Daten fokussierten Bereich (ETH/UNI/FH) oder ausreichend relevante Berufserfahrung. | Erfahrung in der Analyse komplexer Datensätze, idealerweise im E-Commerce-Umfeld. | Fundierte Kenntnisse in der Extraktion und Verarbeitung von Daten mit SQL und Python. | Erfahrung in Konzeption, Umsetzung und statistischer Auswertung von Online-Experimenten (z. B. A/B-Tests) sowie weiterer Methoden der Kausalanalyse. | Kenntnisse im Einsatz von Business-Intelligence-Software wie Tableau oder Looker Studio zur Visualisierung von Daten. | Kenntnisse in Data Science, Machine Learning und Software-Entwicklungspraktiken (z. B. Versionskontrolle) sind von Vorteil. | In Englisch und Deutsch zu arbeiten fällt dir leicht. Die Teamsprache ist Deutsch.",Data Science
36,Product Lead Sourcing & Purchasing,Brack.Alltron AG,Zürich und/oder Mägenwil,"Du führst fachlich durch fundiertes Verständnis der Unternehmensstrategie und tiefes Produktwissen in Deinen Bereichen – von Nutzerbedürfnissen über Markttrends bis hin zu technologischen und strategischen Anforderungen. | Du entwickelst unsere Systeme rund um die Beschaffung und Einkauf mit Blick auf Wirtschaftlichkeit und Zukunftsfähigkeit, identifizierst Potenziale und Synergien und realisierst nachhaltige Lösungen gemeinsam mit Deinem funktionsübergreifenden Team | Du stellst den benutzerorientierten Produkterfolg sicher, indem du neue Funktionen effektiv kommunizierst und relevante Stakeholder wie Commercials / Category Management, Sales und das Management aktiv einbindest. | Du nutzt deinen Methodenbaukasten, um Produkte unternehmerisch weiterzuentwickeln – mit einem klaren Fokus auf Effizienz, Nutzerbedürfnisse und technische Machbarkeit. | Du bist Teil eines agilen Teams und arbeitest hands-on aktiv an der Konzeption und Entwicklung nachhaltiger, skalierbarer technischer Lösungen für die Bereiche Beschaffung und Einkauf mit. | Du verantwortest die Produkt-Roadmap, deren Priorisierung sowie die kontinuierliche Evaluierung neuer Potenziale. | Du bist verantwortlich für die Analyse, Konzeption und Umsetzung neuer Features und Innovationen – von der Idee bis zum Going-Live. | Du treibst technologische Innovationen und Verbesserungen für diese Bereiche aktiv voran, hältst dich über Branchentrends und neue Technologien auf dem Laufenden und evaluierst deren Potenzial für unsere Plattform. | Du leitest die Auswahl und Einführung neuer Technologien her sowie etablierst Best Practices im Team.","Ein abgeschlossenes Studium der Wirtschaftsinformatik, Informatik, Data Science oder Betriebswirtschaftslehre mit dem Schwerpunkt Digitales Marketing oder vergleichbarer Abschluss. | Erste einschlägige Berufserfahrung im E-Commerce, idealerweise im digitalen Produktmanagement von Business Applications rund um Einkaufs- und Beschaffungssystemen inkl. Supplier Data Management | Fundiertes Verständnis agiler Softwareentwicklung und deren Methodiken wie Scrum und Kanban | Sehr gute Kommunikationsfähigkeiten, Überzeugungskraft und Durchsetzungsvermögen, Empathie | Sehr gutes Gespür für Benutzerbedürfnisse und deren Denkweisen und Absichten | Ausgeprägte analytische und konzeptionelle Fähigkeiten sowie hohe Problemlösungskompetenz und Kundenorientierung. | Gute Kenntnisse und sicherer Umgang mit gängigen KI- und LLM-Tools, einschliesslich Erfahrung im Prompt-Engineering, deren APIs und dem effizienten Einsatz von Embeddings. | Strukturiertes, selbständiges und kooperatives Arbeiten in einem interdisziplinären Team | Gutes Grundverständnis für zukunftsweisende Technologien, Systeme und Marktentwicklungen bei Einkaufs- und Beschaffungssystemen inkl. Supplier Data Management | Intrinsische Motivation, kontinuierlich relevante Optimierungspotenziale aufzuspüren und entsprechende Initiativen zu gestalten",Data Science
37,Applied Machine Learning Engineer (80 %),Zentralbibliothek Zürich,Zürich,"unsere digitalisierten Bestände mit zusätzlichen Metadaten für multi-modales Retrieval anzureichern, | grosse Datenkorpora wie zum Beispiel aus dem Google-Books-Projekt mittels ML-Methoden wie Topic Modelling, Named Entity Recognition, Vergabe von Schlagwörtern oder Visualisierungen zu erschliessen, | die Zugänglichkeit unserer Daten zu verbessern, zum Beispiel durch natürlichsprachliche Such- und Empfehlungsfunktionen, Relevanz-Ranking, Auflistung inhaltlich ähnlicher Literatur, Zusammenfassungen oder Übersetzungen, | die Datenerschliessungsprozesse in der ZB weiterzuentwickeln, | Forschende bei dem Zusammenstellen von massgeschneiderten Korpora zu unterstützen | Abgeschlossenes Hochschulstudium in Informatik, Data Science, Computerlinguistik oder gleichwertige Ausbildung in einem verwandten Bereich | Einschlägige Erfahrung in der Anwendung von Machine Learning-Verfahren und von Natural Language Processing-Modellen, idealerweise mit Schwerpunkten auf Textverarbeitung und Textgenerierung | Exzellente Programmierkenntnisse in Python und Erfahrung mit Deep Learning-Frameworks wie TensorFlow oder PyTorch | Fundiertes Verständnis von Datenbanken, Datenintegration und Datenbereinigung | Ausgeprägte Kundenorientierung und Kommunikationsfähigkeit | Initiative, lösungsorientierte und teamfähige Persönlichkeit | Erfahrungen mit methodischer Projektarbeit und Interesse an agilen Arbeitsweisen | Sie arbeiten mit Neugier und Wissensdurst und bringen sich gerne mit guten Vorschlägen ein | Deutschkenntnisse auf Muttersprache-Niveau und gute Englischkenntnisse in Wort und Schrift",no skills found on this job ad,Data Science
38,Mendix Tech Consultant (all genders),adesso Schweiz AG,Deutschschweiz,"Participate in the full software development lifecycle - Analyze, understand and document software and business requirements; conceptualize and design architecture and structure; design and implement scalable databases; develop web and mobile applications; develop, design and execute comprehensive test scenarios and troubleshooting; set up, manage and track deployment/processes; and maintain through ongoing support and gathering new requirements or enhancements. | Work as part of a project team - offer guidance, feedback, and conduct code reviews. Actively participate in scrum ceremonies. Experience with agile methodologies and proficiency in at least one Scrum framework is mandatory. Additionally, you’ll collaborate with stakeholders, project managers, and solution architects to analyze system specifications, translate them into system requirements, and provide strategic guidance to ensure the project's successful delivery. | Sound knowledge: Degree in computer science, business informatics, data science or a comparable field of study with a relevant connection. | Experience: 2-3 years of professional experience with Mendix. | Certification: Mendix Rapid Certification. | Language skills: Fluent in English and either German (C1), French (C1) or Italian (C1), depending on the location. | Learn and grow with us: we support your continuous development with over 400 training courses and our digital learning platform. | Experience real team spirit: joint events (e.g. ski weekends and the annual eduCamp training trip), welcome days and company runs strengthen our team spirit and allow you to be part of the team from the very beginning. | Commitment that is rewarded: Your commitment pays off - with bonuses for recommendations, lectures, thesis supervision and attractive benefits via our corporate benefits portal.","Development skills: You have already developed with JavaScript, CSS, Python, Java, PHP and PostgreSQL. You are familiar with asynchronous processes such as timers and task queues. | Certifications: Mendix Intermediate and/or Advanced certification. | Automation skills: Development of CI/CD pipelines with Mendix. | Methodology experience: You have experience in BDD (Behavior-Driven Development), TDD (Test-Driven Development), JUnit frameworks and test automation.",Data Science
40,Business Analyst Material Science,Omya (Schweiz) AG,Egerkingen,"Analyze business, market, customer, and competitor data to provide basis for actionable recommendations in terms of portfolio and/or business opportunities or gaps. | Provide input to establish targets for sales performance for Market/Segment portfolio, such as product mix, sales volume, market share, or business development. | Develop dashboards and reports to monitor market trends, segment performance, and campaign effectiveness. | Collaborate with Sales Excellence team to ensure robust and scalable insight generation. | Measure and report segment growth vs. previous years and strategic plans. | Analyze business metrics for strategic ""solutions"" and provide actionable insights, especially on product mix gaps. | Track sales performance including profitability, volumes, market share, and cross-selling scores. | Support gap analysis for global Key Accounts and vs. target account plans as needed. | Develop and monitor KPIs for strategic projects and target market opportunities. | Deliver timely, accurate reports and recommendations to Segment Head, Portfolio Directors, and Key Account Managers. | Provide competitive intelligence (imports, market benchmarks, competitor activity). | Build and maintain predictive analytics tools. | Leverage AI and CRM (Salesforce) data to uncover trends and opportunities.","Bachelor's or Master's degree in Business Analytics, Economics, Engineering, or related field. | 3+ years of experience in business analysis, preferably in B2B industrial or chemical sectors. | Strong analytical and problem-solving skills. | Data Analysis and management (e.g. Python, SQL, NoSQL) | Proficiency in data visualization and BI tools (e.g., Power BI, Tableau). | Experience with CRM systems (Salesforce preferred) and AI-based analytics. | Excellent communication and stakeholder management skills. | Ability to work cross-functionally in a global matrix organization. | Mindset: Strategic thinker with a hands-on attitude. Curious, proactive, and solution-oriented. | Excellent command in English, both oral and written. | Good command of both oral and written additional relevant language is beneficial, particularly German.",Data Science
44,Contractor - IT System Engineer,Humanis AG,Deutschschweiz,"Operate and enhance an in-house collaboration platform | Build and maintain CI/CD pipelines for automated software delivery | Manage on-premises systems and Kubernetes clusters securely and efficiently | Automate infrastructure provisioning using IaC (Ansible/Terraform) | Implement monitoring, logging, and alerting (ELK, Prometheus, Grafana) | Integrate and optimize real-time data streams with Apache Kafka | Support test automation and ensure system reliability (JUnit, Selenium, TestNG) | Maintain architecture compliance and present solutions to engineering teams | Manage agile workflows and documentation using Jira, Confluence, and GitLab | MSc or BSc in Computer Science, Engineering, or related field | At least 2–3 years of professional experience in a similar role (DevOps / System Engineering) | Strong expertise in CI/CD, Kubernetes, IaC, and Linux system administration | Experience in architecture-driven development and implementation reviews | Independent, structured, and communicative working style | Ability to explain complex technical topics in a clear and understandable way | Fluent in German (native) with good English skills | Willingness to commute or relocate to the Bern area | Exciting IT projects in a modern and innovative technical environment | Attractive employment conditions and remuneration. | Social benefits",no skills found on this job ad,Data Science
48,Data Analyst,netplus.ch SA,Sierre,"Révéler l'invisible : Explorer, collecter et interpréter nos ensembles de données pour identifier des tendances et les opportunités de croissance, que vous traduirez en tableaux de bord décisionnels percutants. | Construire l'avenir de la donnée : Participer activement à la construction d'un environnement de données robuste, sécurisé et pérenne. | Anticiper pour mieux agir : Développer et maintenir des modèles statistiques et prédictifs pour formuler des recommandations. | Collaborer et communiquer : Travailler en étroite collaboration avec les équipes métiers pour comprendre leurs besoins.","Qualités Personnelles : Vous êtes reconnu(e) pour votre rigueur, votre curiosité et votre solide esprit d'analyse. Proactif(ve) et autonome, vous savez résoudre des problèmes complexes et proposer des solutions innovantes.",Data Science
50,Senior Software Engineer mit AI/ML Erfahrung,RUAG AG,Bern,"Entwicklung und Pflege von Softwarelösungen zur Integration von ML-Modellen in Produkte und Plattformen | Design und Implementierung skalierbarer APIs und Services für ML-Modelle | Aufbau von Daten- und Modell-Pipelines mit Fokus auf Zuverlässigkeit, Sicherheit und Effizienz | Zusammenarbeit mit Data Scientists und ML-Engineers bei der Umsetzung von Modellen in produktive Systeme | Anwendung von Best Practices im Bereich Softwarequalität (Clean Code, Testing, CI/CD, Code Reviews) | Monitoring, Debugging und Optimierung bestehender ML-gestützter Anwendungen","Bachelor oder Master-Abschluss in Computer Science oder benachbartem Gebiet | Mehrjährige Erfahrung als Softwareentwickler z.B. in Python, Java oder C++ | Erfahrung mit Containerisierung und Orchestrierung (Docker, Kubernetes, OpenShift) | Teamorientierte Arbeitsweise mit Schwerpunkt auf Zusammenarbeit und Anpassungsfähigkeit | Sehr gute Deutsch- und Englischkenntnisse in Wort und Schrift",Data Science
53,(Senior) Consultant - Technology Strategy & Transformation - Financial Services (80-100%),EY (Ernst & Young AG),Zurich,"Understand clients' business needs to align IT strategies effectively. | Create live demos for relevant use cases and stay informed on emerging technologies (Cloud, Data Analytics, ML & AI, Process Mining, etc.), assess their market impact and relevance to clients' current and future business models. | Facilitate business transformation by leveraging technology and applying agile and waterfall methodologies. | Manage technology-driven projects, including resource allocation, activity planning, and work product oversight. | Assist in IT cost optimization initiatives to enhance financial efficiency. | Participate in assessment, design, and IT implementation projects, providing vital support. | Analyze data to derive insights and propose actionable strategies. | Communicate findings and deliverables clearly to clients and senior team members. | Work collaboratively in dynamic, cross-functional teams to achieve project goals.","A passion for Information Technologies, Digital Innovation and Financial Services | A degree in Business Information Technology, Information Technology, Computer Science, Business Administration with a strong technology affinity, or equivalent | Fluency in German and English; French and Italian beneficial | First working experience in technology consulting or a technology delivery environment in Financial Services (Banking & Capital Markets, Wealth & Asset Management, or Insurance) | Strong analytical skills with an ability to structure and analyze problems in a systematic and organized way | The ability to break down and structure complex matters and communicate them effectively to senior stakeholders | An open-minded motivated personality willing to work in teams | An entrepreneurial mentality with the willingness to drive and own solutions | Can-do mindset, with a focus on high performance standards and ability to work in a focused and independent manner | Coding and prompt engineering capabilities",Data Science
65,Data & Analytics Engineer (Jr/Mid-Level) (f|m|d) | 100% | Zurich - Hybrid Work,SMG Swiss Marketplace Group,Zürich,"Design, build, and maintain scalable data pipelines (ETL/ELT) and transformation workflows | Provide accurate and timely metrics, dashboards, and reports to meet group-level needs | Develop data applications and visualisations that enable stakeholders to access and act on insights | Support data governance and compliance processes to ensure consistent, accurate, and trustworthy data | Partner with business teams to translate requirements into impactful data products that drive operational excellence.","80% Backend - pipelines, transformations, data apps | 20% Frontend - dashboards, visualisations",Data Science
83,SAP Security Architect / SAP IAM (m/f),BROMsolutions AG Biel,Zentralschweiz,"Continuously assess and manage the security and risk posture across the SAP and enterprise application portfolio | Guide IT business partner teams in designing and delivering secure SAP and business application solutions | Define and standardize authorization concepts in support of our IAM initiatives, ensuring consistency across platforms such as SAP, Veeva, and Kinaxis | Lead the development of integration security standards for APIs, data exchanges, and authentication mechanisms | Classify business applications and align security controls based on criticality, organizational value streams, and process sensitivity | Collaborate closely with security, enterprise architecture, infrastructure, and application teams to implement comprehensive SAP cloud and SaaS security models","Bachelor’s or Master’s Degree in computer science, Information Security, or related discipline | 5+ years of experience in IT Security for enterprise application like SAP, including 2+ years in security architecture | Knowledge of enterprise/security architecture frameworks (e.g. TOGAF, SABSA) and business capability modeling | Hands-on with IAM systems and the development of SAP authorization models and role concepts | Solid understanding of cloud security architectures (AWS, Azure, SAP BTP, private/hybrid cloud) | Proactive, structured and responsible approach to work | Strong collaboration, communication and documentation skills in English (German is a plus)",Data Science
84,Cybersecurity and Privacy GRC Specialist,PwC,Zürich,Areas of responsibility:,Broad spectrum:,Data Science
92,Senior Consultant - Technology Consulting - Cyber Security (80-100%),EY (Ernst & Young AG),Zürich,"Your focus will be on Cybersecurity consulting, information security, and risk assessment of processes, applications, systems, and IT infrastructures in banks and insurance companies | You will work on projects in hot topics in Cybersecurity such as cloud security, blockchain, DevOps, penetration testing, and security architecture | In addition, you will also take on tasks in the areas of IT risk assurance in terms of internal controls and risk and compliance management | As a member of an interdisciplinary team of specialists, you will support our customers in consulting projects in assessing and improving the effectiveness and quality in the field of Cybersecurity | Help our clients understand the Cyber threat landscape and assess the maturity of their Cybersecurity strategy","Degree (Bachelor's or Master's) in Business Information Technology, in a technical field (e.g. Computer Science) related to Cybersecurity topics, or equivalent education | Relevant professional experience (at least 2 - 3 years) in Cybersecurity, information security and technical IT security assessments | Sound organizational and technical knowledge in the area of Cybersecurity including experience with relevant security standards and frameworks (e.g. ISO 27001:2013, NIST Cybersecurity Framework etc.) | A must: Passion for consulting and Cybersecurity topics and an in-depth experience in one or more Cybersecurity areas such as (but not limited to) security architecture, data protection, network security, or identity and access management | Ideally, relevant industry certifications (e.g. CISSP, CISM, CRISC, CISA, etc.) | A plus: Previous knowledge of the financial services sector | Qualities guaranteed to boost your career at EY: ability to work in a team, determination, commitment, a strong presence, an independent working style, and a quick grasp of new topics | Fluent in German and English",Data Science
93,"Personal-Assistent 80-100%, m/w",Nicht offengelegter Arbeitgeber,Burgdorf,Mithilfe in der Personaladministration vom Eintritt bis zum Austritt | Führen der Zeiterfassung | Mithilfe bei der Rekrutierung | Unterstützung in der korrekten und termingerechten Abwicklung der Lohnzahlungen und Sozialversicherungen | Allgemeine administrative Tätigkeiten im HR-Bereich,"Kaufmännische Grundausbildung | Weiterbildung als Personalassistent/in ist zwingend | 3-5 Jahre Berufserfahrung im HR | Sehr gute Deutschkenntnisse | Gute PC-Kenntnisse und gutes Verständnis für Zahlen | Erkennen von Schnittstellen und vernetztes, unternehmerisches Denken | Selbständige, analytische und exakte Arbeitsweise",Data Science
133,Senior Backend Engineer (a)*,Ringier AG,Zürich-Seefeld,"You will play a significant role in major technical initiatives and projects, assisting in optimizing data pipelines and enhancing service performance | You will contribute to our evolving software architecture and crucial technology decisions | You will build and maintain backend services, ensuring reliability, performance, and scalability","You possess a Bachelor's degree in Computer Science or equivalent and have 6+ years of professional experience in software development | You demonstrate strong programming skills in Node.js, Typescript, and Javascript | You have a solid understanding of backend technologies such as Redis, NoSQL, SQL Databases, and frameworks like NestJS or Express | You possess a solid grasp of AWS Services like SQS, Lambda, DynamoDB, S3, and API Gateway | You have deep knowledge of caching strategies to unload the origin | You are familiar with GraphQL, containerized development, and hosting (Docker) | You are fluent in English; German language proficiency is a plus",Data Science
135,Senior DevOps Engineer (a)*,Ringier AG,Zürich-Seefeld,"You will play a significant role in major technical initiatives and projects focused on optimising data pipelines, improving service performance, and ensuring infrastructure scalability | Participate actively in evolving the software architecture and making key technology decisions with a strong emphasis on cloud infrastructure best practices | Design, develop, and maintain scalable, reliable backend services to meet high-performance standards","Bachelor's degree in Computer Science or a related field, with 6+ years of professional software development experience | In-depth knowledge of backend technologies, including Redis, NoSQL and SQL databases, and frameworks such as NestJS or Express | Solid experience with AWS services: SQS, Lambda, DynamoDB, S3, and API Gateway | Advanced understanding of caching strategies to optimise origin load | Expertise in CI/CD pipelines and GitOps methodologies, including Infrastructure as Code using Serverless Framework and AWS CloudFormation | Strong proficiency with container orchestration, specifically Amazon EKS or Kubernetes | Skilled in monitoring, securing, and optimising AWS environments using Datadog and native AWS tools | Experience with JavaScript/TypeScript (e.g., Node.js) or other modern programming languages | AWS certifications (e.g., AWS Certified DevOps Engineer, AWS Solutions Architect) are highly desirable | Fluent in English; German language skills are a plus",Data Science
137,IT System Engineer,RUAG AG,Emmen,"You will keep our Linux and Windows servers and clients up and running and ensure that our network remains stable and secure | You will assist in setting up a secure IT infrastructure, support certifications such as ISO 27001 / TISAX and train our employees in IT security | You will keep an eye on the market, evaluate new hardware and software, maintain supplier contacts and ensure that our team is optimally equipped | You will assist our employees with IT issues, document our IT infrastructure and ensure smooth operations | You will ensure that the right software and data are available for our wind tunnel tests, accompany test runs and step in on call in emergencies | You will develop smart software solutions, automate processes and apply your expertise in C/C++, Python, Shell Scripting or LabVIEW for innovative applications | You will set up software development tools, version control and CI/CD pipelines and keep our development processes running smoothly","You have a university degree (bachelor's or master's) in computer science or a similar field and have gained sound knowledge at a university of applied sciences or university | good Linux and network skills | Scripting languages and Unix systems are your everyday tools, which you use with confidence. | Experience in C/C++ programming | Knowledge of Python and LabVIEW is an advantage | You enjoy working in a team, but are also independent, structured and responsible. | You are confident in German (level C1) and have a good command of English.",Data Science
150,Senior Manager Finance - Vitamins Unit Commercial,dsm-firmenich,Kaiseraugst,"Collaboration & Process Setup: Partner with the Commercial Relationship Lead to define ways of working, SOPs, reporting requirements, and performance metrics to meet contractual obligations with the global key customer | Financial Oversight: Oversee commercial agreement results, prepare annual pricing, implement cost control measures, and manage financial KPIs | Project & Performance Monitoring: Establish project control mechanisms and regularly review overall financial performance, including compliance, pricing, and operating working capital | Reporting & Audits: Design and execute quarterly reconciliations, coordinate data and reporting for Operational Committee meetings, and handle audit requests | Stakeholder Management: Lead stakeholder engagement and resolve operational and financial issues effectively | Contractual Validation: Implement monthly, quarterly, and annual validation processes in line with contractual requirements","Unique career paths across Animal Nutrition & Health - explore what drives you and get the support to make it happen | A science led company, cutting edge research and creativity everywhere – from biotech breakthroughs to sustainability game-changers, you’ll work on what’s next | Growth that keeps up with you – you join an industry leader that will develop your expertise and leadership | A culture that lifts you up – with collaborative teams, shared wins, and people who cheer each other on. | Customer-first approach, turning ideas into impactful solutions",Data Science
156,Senior Splunk Engineer - private banking,Synechron Switzerland,Zürich,"Monitoring strategies and providing best practices in coordination with internal Ops/Support teams, developers, and business owners, while monitoring the performance and availability of Splunk systems. | Managing the ticketing system incident and change management queues as needed, participate in rotating on-call support for Enterprise Management platforms. | Installing, deploying, and supporting Enterprise Splunk services, including performing scripted installations and configurations. | Managing Splunk knowledge objects such as apps, dashboards, saved searches, scheduled searches, and alerts. | Developing and evaluating tools (e.g., SolarWinds, New Relic). | Supporting existing Splunk information security applications in areas like security, monitoring, task automation, continuous integration, deployment, and performance optimization. | Using Splunk to collect and index log data, developing queries, and providing logging integration support. | Working closely with application owners to create and maintain applications for tracking and updating. | Serving as the SME for all technical Splunk issues across departments and design a resilient Splunk infrastructure while providing ongoing support. | Developing and mentoring others on Splunk usage.","You hold a Bachelor?s degree in Computer Science, Engineering, or relevant field. | You justify a Senior level of experience with one scripting language, such as JavaScript, Java, Python, Perl, Groovy, Ruby, Korn. | You possess a working understanding in data analytics Hadoop, MapReduce, R, Alteryx, Prelert, Tableau, D3/JavaScript visualizations. | You are experienced with security of the base CentOS servers for Splunk. | You have a working experience in data warehousing and/or business intelligence systems. | You are familiar and have worked before with designing and implementing large, scalable web services. | You have experience with scripting in UNIX or LINUX. | You have worked with tiered environments (Sandbox, Staging, UAT, Production). | You consider yourself somebody who can collaborate and listen with technical and non-technical stakeholders. | You can easily work in the English language. | You are a Swiss resident.",Data Science
172,Lead DevOps Engineer – cloud application,Mettler Toledo,Nänikon-Greifensee,"Technical lead of the DevOps Team (10 team members) | Oversees the backlog of all DevOps activities. Works closely together with project managers regarding prioritization and execution of DevOps activities. | Work closely with your cooperation partners who are Architects, test-automation-teams and software development teams. | Plan, design, implement and test application deployment strategies | Develop solutions to automated deployment of production and testing environment | Evaluate and integrate appropriate tools for monitoring, tracing and diagnosing applications | Review and analyze product and system specifications and provide technical recommendations in your field of expertise | Guide and train teams on best practices regarding container deployment, testing and management | You have at least a bachelor's degree (FH / University) in computer science, IT or related technical/scientific discipline | You bring several years of work experience in leading a technical team, Familiarity with phase models and agile methods | Proficiency with DevOps and Infrastructure as Code (preferably in Azure DevOps) and in deploying and securing container-based systems such as Docker, Kubernetes on private and public clouds | You are experienced in programming languages and/or scripting languages, e.g. C#, Python, Shell | You bring a good knowledge of operating systems, especially Linux, general networking, cloud infrastructure, system monitoring, and operating CI/CD pipelines | You are fluent in English, oral and written, with good communication skills. German is a plus | Flexible working hours (depending on the role), a hybrid work model, and a wide portfolio of training opportunities | A 40-hour work week with at least 25 vacation days per year, plus 4 to 7 additional days off between bank holidays | Free parking and direct access to public transport | Healthy lunches cooked onsite at our own METTLER TOLEDO restaurant, with special prices for employees | We offer a dynamic and innovation-driven corporate culture that promotes teamwork, personal development, and a passion for excellence. | A range of additional attractive benefits, including employee discounts at select area businesses",no skills found on this job ad,Data Science
174,Security System Engineer (m/f/d),Ronal AG,Härkingen,"Design and implement security measures for systems built on Microsoft technologies, including Windows Server, Azure, and Microsoft 365 | Configure and manage Microsoft security tools such as Defender for Endpoint, Defender for Identity, and Defender for Cloud | Design and implement secure remote access solutions for employees and third parties using Microsoft technologies, such as VPNs, Remote Desktop Services (RDS), and Azure Virtual Desktop (AVD), or third-party solutions | Configure and manage security controls for remote access tools, including Microsoft Intune for endpoint protection and Azure Conditional Access | Respond to alerts and investigate incidents using Microsoft security tools | Enforce compliance policies using Microsoft Purview for data classification and protection | Ensure alignment with frameworks like TISAX, GDPR, or NIST using Microsoft Compliance Manager | Secure Windows operating systems, SQL Server, and other Microsoft applications against vulnerabilities | Apply security baselines and hardening configurations using Group Policy and Microsoft Security Compliance Toolkit | Bachelor's degree in Computer Science, Information Technology, or a related field | Certifications: Relevant Microsoft certifications, such as Microsoft Certified Security, Compliance, and Identity Fundamentals, Azure Security Engineer Associate, Information Protection Administrator Associate | Several years of experience in IT security | Expertise in Microsoft Defender suite (Endpoint, Identity, Cloud, Office 365) | Proficiency in securing and managing Windows Server (2016, 2019, 2022) and Windows 10/11 | Hands-on experience with Active Directory and Azure Active Directory (AAD) for identity management | Strong understanding of network security principles, including firewalls, VPNs, and virtual networks in Azure | Knowledge of system hardening techniques and security baselines using Microsoft Security Compliance Toolkit and Group Policy | Proficiency in configuring and securing Microsoft Azure services, including Azure Security Center | A challenging environment in a global company that leads the industry | Hybrid working model with up to two remote workdays per week | Attractive employment conditions, professional development, and career growth opportunities | A collaborative and forward-thinking team culture",no skills found on this job ad,Data Science
196,Associate Consultant / Consultant Financial Services (Focus CRM) (Salesforce / BSI),Synpulse Schweiz AG,Zürich,"Advising our customers (banks & insurance companies) on the conception of CRM and MarTech solutions | Analysing customer journeys and business requirements to design tailored CRM strategies and data-driven solutions | Participation in varied projects for the introduction of CRM solutions (requirements engineering, system configuration on a no-/low-code base, testing, change management) | Assist in planning and managing project deliverables, timelines, and stakeholder communications | Supporting the acquisition of new customers and projects for our company | Collaboration with customers and ecosystem partners | Very good Bachelor or Master's degree from a renowned university or university of applied sciences in Information Technology and/or Business (focus Financial Services) | IT affinity and interest in complex IT systems | Strong problem solving and troubleshooting competences | Very good language skills (min. B2 level) in German and English | Strong communication skills and ability to engage with stakeholders from both business and IT | Structured and goal-oriented way of working

As a plus:
- First experience in consulting, business analysis, or project management
- Programming skills like Java, Python or Javascript | You’ll fast-track your development by diving into financial business models, cutting-edge technologies, and real-world client challenges – all while shaping your own path. #YourGrowthUnleashed | You are growing your skills and experiences in understanding business models of financial companies, new technologies and solutions | Competitive salary and attractive benefits aligned with the market | Bright, modern office spaces in central locations with excellent public transport access | A hands-on mentality and a strong team spirit | Fun events, learning opportunities, and initiatives shaped by our people | Modern working environment and flexible working models | CV | Qualifications (bachelor/ master diploma, etc.) with certificate of grades | Motivation letter: Why Synpulse? Why you? Why this function? | Recommendation letters (optional)",no skills found on this job ad,Data Science
200,Ingénieur IA & Data Science,Moraine SA,Lausanne,"Identifier et prioriser les cas d’usage stratégiques (maintenance prédictive, cybersécurité cognitive, optimisation de l’offre, assistant voyageur…). | Concevoir des architectures AI-native : gouvernance et qualité des données, data lakehouse & feature store, pipelines MLOps, intégration IoT et temps réel. | Développer et industrialiser la chaîne complète IA : collecte, préparation, modélisation (ML, deep learning, LLM), déploiement (micro-services, edge, on-device). | Garantir la conformité éthique et réglementaire (EU AI Act, RGPD). | Documenter les solutions, transmettre les compétences et accompagner les équipes internes vers l’autonomie.","Diplôme en informatique, mathématiques appliquées, IA ou équivalent. | Expérience avérée en data science et ingénierie IA. | Solide maîtrise des techniques de machine learning, deep learning et traitement des données massives. | Connaissance des pipelines MLOps et des architectures data modernes. | Sensibilité aux enjeux éthiques et réglementaires (RGPD, AI Act). | Capacité à transformer un prototype en solution industrialisée, avec un impact mesurable. | Le lieu du poste est à Genève, si vous pouvez faire le déplacement, vous pouvez candidater.",Data Science
223,Business Analyst - Junior Projektmanager 80-100%,Seniorendienste Schweiz AG,Rheinfelden,"Zusammenarbeit mit Stakeholdern, Interviews, Workshops, Umfragen führen, analysieren und dokumentieren | Bewertung der Geschäftsprozesse, Identifizierung von Ineffizienzen und optimierte Arbeitsabläufe vorschlagen | Datenanalyse die zur Strategieentwicklung beitragen | Zusammenarbeit mit technischen Teams zur Integration von Lösungen | Erstellen von Dokumentationen | Benutzertests durchführen und validieren | Unterstützung bei Projektplanung und -umsetzung | Support und Schulung bei Einführung neuer Prozesse oder Systeme","Bachelorabschluss in Betriebswirtschaft, Informationstechnologie oder einem verwandten Bereich | 2 Jahre Berufserfahrung als Business Analyst oder in einer ähnlichen Position | Beherrschung von MS Office Tools und Visio | Zusätzliche Kurse wie PMP sind von Vorteil | Vertrautheit mit Datenanalyse-Tools von Vorteil | Grundlegendes Verständnis von Projekt- und Softwareentwicklungs-Methodiken | Ausgeprägte analytische Fähigkeiten und Problemlösungskompetenz | Ausgezeichnete Kommunikations- und zwischenmenschliche Fähigkeiten | Prioritäten setzen und mit Termindruck umgehen können | Erfahrung im Gesundheitswesen und in der häuslichen Pflege ist von Vorteil | Sehr gute Deutsch- und Englischkenntnisse, Französischkenntnisse von Vorteil",Business Analyst
226,Senior IT Business Analyst Insurance (all genders),BSI Business Systems Integration AG,Zürich,"Du wirst zur Expertin für unser Produkt und bringst dieses Wissen und dein Versicherungsbranchen Know-how in die Projekte ein | Du arbeitest an der Anforderungsaufnahme, Konzepterstellung und am Lösungsdesign für geschäftskritische Softwaresysteme | Du bist für die Lösungen im Projekt verantwortlich und schaffst echten Mehrwert für unsere Kunden | Du führst unsere Kunden aktiv von Beginn an bis zum Abschluss des Projektes, bist die erste Ansprechperson für eine erfolgreiche Zusammenarbeit | Du bist bereit, Anforderungen konfigurativ und mit Low Code umzusetzen | Dabei arbeitest du mit Kollegen und unseren Kunden in einem interdisziplinären, agilen Team | Unser Produktportfolio bringst du mit deinen Innovationen weiter | Abgeschlossenes Studium in Wirtschaftsinformatik, Betriebsökonomie oder vergleichbare Qualifikation | Mehrjährige Berufserfahrung als Business Analyst für Versicherungskunden | Leidenschaft für moderne Softwarelösungen | Konzeptionelle und analytische Fähigkeiten | Ausgeprägte Kommunikations- und Präsentationsstärke in Deutsch und Englisch | Initiative, Kreativität, Verantwortung, Teamgeist | Unternehmerische Gestaltungs- und Beteiligungsmöglichkeiten in wertschätzender Firmenkultur frei von Hierarchien | Persönliche Betreuung und unser Weiterbildungsbudget für deine Entwicklung | Beitrag zum Mittagessen (Lunch Check) | Flexible Arbeitszeiten und Orte | Möglichkeit zum Ferienkauf, Sabbatical und Workation innerhalb der EU",no skills found on this job ad,Business Analyst
230,Business Analystin/Analyst (80–100%),ZWEI Wealth Experts AG,Zürich,"Anforderungen mit Biz Stakeholdern aufnehmen, strukturieren, priorisieren, konkretisieren | In umsetzbare Konzepte/Specs/Acceptance Criteria übersetzen und detaillieren | Sicherstellen reibungsloser Kommunikation zwischen Biz Stakeholdern und IT","Mit unserem onshore IT-Partner die Plattform verbessern: Sprints begleiten, Reviews/UAT durchführen, Backlog pflegen | Fachliche Vertretung, saubere Doku, Projektleitung",Business Analyst
248,Avaloq Developer / Business Analyst 80-100% (w/m/d),LGT,Zürich,"Enge Zusammenarbeit mit Ihrem interdisziplinären, agilen Team. | Übersetzen Sie Geschäftsbedürfnisse in funktionale Spezifikationen für die IT. | Sie entwickeln neue Funktionen in Avaloq und erweitern bestehende Funktionen. | Validierung von Lösungen durch Testen, um sicherzustellen, dass sie die spezifizierten Anforderungen erfüllen und die gewünschten Ergebnisse liefern. | Erstellen und unterstützen Sie Systemlösungen. | Höhere technische Ausbildung und Weiterbildung (Wirtschaftsinformatik, Anwendungsentwicklung) | Fundierte Kenntnisse in Avaloq und seinen Konzepten wie Schnittstellentechnologien, Objektmodell, Workflow-Engine, etc. | Bankfachliche Kenntnisse in Anlageprozessen | Kenntnisse in PL/SQL und Oracle SQL von Vorteil | Flair für konzeptionelles und analytisches Arbeiten (Analyse, lösungsorientiertes Denken) | Fliessendes Englisch in Wort und Schrift, Deutsch ist von Vorteil | Teamfähige und kommunikative, belastbare Persönlichkeit mit Eigeninitiative, Umsetzungsstärke und hoher Sozialkompetenz | Systematische, strukturierte und selbständige Arbeitsweise | Flexible Arbeitsmodelle | Sabbaticals | Mindestens 25 Tage Jahresurlaub, abhängig vom Alter | Optionen für bezahlten Sonderurlaub | Mutterschafts- und Vaterschaftsurlaub, Möglichkeiten für zusätzlichen Elternurlaub | Zusätzlicher Kinderbetreuungszuschuss für entgeltlich fremdbetreute Kinder bis 12 Jahre | Interne Kurse | Externe Kurse an der Liechtenstein Academy | Unterstützung für externe Aus- und Weiterbildungen | Coaching- und Mentoring-Programme | Internationale Einsätze | Intrapreneurship-Programm | Rabatte auf Bankprodukte und Dienstleistungen der LGT | Co-Investments bei der LGT | Rabatte auf Kranken- und Sachversicherungen | Pensionsplan mit individuellen Optionen | Verschiedene Initiativen zur Förderung der Mobilität/E-Mobilität | Anerkennung wichtiger Lebensereignisse | Wellness- und Gesundheitsprogramme | Subventionierte Fitness- und Yoga-Kurse | Gesunde Mahlzeiten | Täglich frisches Obst",no skills found on this job ad,Business Analyst
251,4 Product Owner Digitalprodukte,Bundesamt für Gesundheit BAG,Liebefeld,"Produktverantwortung übernehmen und digitale Lösungen mit Mehrwert entwickeln – im Einklang mit der Strategie des EDI, des Amtes und des Programm DigiSanté | Anforderungen der Benutzer, des Faches und der Stakeholder erfassen, priorisieren und in nutzerzentrierte Features überführen | Eine enge Zusammenarbeit mit dem Entwicklungsteam und den Fachspezialisten pflegen, um Anforderungen und das Produkt zu validieren | Verantwortung über die Weiterentwicklung und den Lifecycle des Digitalproduktes anhand einer klaren Produktvision übernehmen | Den agilen Entwicklungsprozess (SAFe und Scrum) mitgestalten und steuern","Über einen Hochschulabschluss in Medizininformatik, (Wirtschafts-)Informatik oder einer vergleichbaren Fachrichtung verfügen | Mehrjährige Erfahrung als Product Owner und / oder in Business Analyse nachweisen – idealerweise im Gesundheitswesen | Kommunikations- und Moderationsfähigkeit in komplexen, interdisziplinären Umfeldern einsetzen, über analytisches Denkvermögen verfügen, die Fähigkeit besitzen komplexe Anforderungen zu strukturieren sowie Kundenbedürfnisse in Features und User Stories zu übersetzen | Sicheren Umgang mit agilen Frameworks (Scrum, SAFe) und Erfahrung mit Tools wie Jira, Confluence ausweisen | Gute Kenntnisse einer zweiten Amtssprache. Vorteilhaft sind auch gute Englisch-Kenntnisse",Business Analyst
263,Analyst Karten und Payments (m/w/d) für flexgold,SOLIT Group AG,Tägerwilen,"Mitarbeiter-Rabatt auf SOLIT-Produkte/-Dienstleistungen (Edelmetalle) | Unbefristeter Arbeitsvertrag | Flexible Arbeitszeiten mit Option auf Mobile Office bei einer 40-Stunden-Woche | Paten-System in der Onboarding-Phase | Kostenlose Parkplätze | Kostenlose Getränke, regelmässiges Mitarbeiterfrühstück und frisches Obst | Ein fantastisches Team, welches mit Ehrgeiz und Innovationskraft das Motto ""make money sound again"" vorantreibt","Du unterstützt uns bei der Business Analyse mit dem Schwerpunkt Zahlungsverkehr (Karten) und neue Bezahlverfahren | Du führst Analyse und Konzeption für effiziente Zahlungsverkehrsprozesse und Abwicklungssysteme (im Bereich Kartenzahlungen) durch | Du übernimmst die vergleichende Analyse verschiedener Kartenmanagementsysteme und Bezahlprozesse | Du führst den Austausch mit Banken und Karten-Netzwerken zu technischen, prozessualen und strategischen Themen | Du überwachst kontinuierlich alle Zahlungsprozesse und bleibst stets auf dem neuesten Stand zu Innovationen im Payment-Bereich",Business Analyst
288,Business Analyst ERP + EDI (m/w/d),Planzer Synergistics,Regensdorf,"Fourth-Party Logistics Provider ist dir ein sehr bekannter Begriff und du kannst die Transport- und Logistikaufträge abwickeln und überwachen | Du übernimmst Verantwortung für sämtliche Digitalisierungs-Projekte und erledigst die Ausarbeitung von intelligenten IT gesteuerten Prozessen (Design) problemlos | Als Projektleiter des Bereichs ERP Entwicklung (CargoWise One) stellst du dein Können unter Beweis | Erstellung von Projektdokumentationen, Prozessanweisungen sowie SOP's sind für dich selbstverständliche tägliche Aufgaben | Beim Kunden setzt du Logistikkonzepte um und überzeugst beratend wie auch betreuend bei Integrationsfragen | 1st und 2nd Level Support für Anwender und Kunden (Steakholder) machst du nebenbei mit Freude | Du bist im Besitz eines abgeschlossenen Studiums als Wirtschaftsinformatiker oder vergleichbares | Deine Erfahrung in ERP-Systeme als Applikationsbetreuer oder Business Analyst sind bereits vorhanden | Deine Kenntnisse in relationalen Datenbanksystemen sind sehr gut | Technisches Verständnis sowie eine analytische Denkweise gehören zu deinem natürlichen Personell | Reisen? Das macht dir Spass und die Bereitschaft für In- und Ausland Travels sind für dich selbstverständlich | Von grossem Vorteil ist bestehende Erfahrung in XML und CVS Mapping | Gute Kenntnisse im Bereich Script basierter Programmiersprachen und mehrjährige Erfahrung im Bereich Logistik runden dein Profil ab | Du kommunizierst sicher auf Deutsch und Englisch in Wort- und Schrift, alle weiteren Sprachen sind ein Plus",no skills found on this job ad,Business Analyst
301,Data & Analytics Spezialist:in 70-100% mit starken technischen Skills,p3b ag,Raum Bern und teilweise im Homeoffice,"Implementierung und Optimierung innovativer Business Intelligence Lösungen auf Basis von Microsoft BI-Technologien | Du übernimmst Verantwortung bei der Migration der bestehenden Infrastruktur auf moderne Azure-Technologien | Entwicklung und Umsetzung von Strategien im Bereich BI | Du engagierst dich in der Haltung, Pflege, Analyse und Visualisierung von geschäftsrelevanten Daten | arbeitest du mit modernen Microsoft Technologien aus dem BI-Bereich | entwickelst du innovative Ansätze zur Optimierung von Datenprozessen | trägst du zur datengetriebenen Entscheidungsfindung bei | tauschst du dich regelmässig mit Kolleg:innen aus verschiedenen Fachbereichen aus | Abgeschlossenes Studium in der Informatik, Wirtschaftsinformatik, Datenwissenschaften oder vergleichbar | Fundierte Kenntnisse in Azure-Technologien (z. B. Power BI, MS Fabric) und/oder Microsoft-BI-Technologie (MSSQL Server, SSAS, SSIS) | Hervorragendes Verständnis von BI-Methoden und -Prozessen sowie Erfahrung in der Entwicklung und Architektur im BI-Bereich | Sehr gute Deutsch- und solide Französischkenntnisse oder sehr gute Französisch- und solide Deutschkenntnisse | Du bist flexibel, offen und neue Herausforderungen machen dir Spass | Stetige Weiterentwicklung ist dir wichtig | Neue Technologien und Herausforderungen motivieren dich | Du zeigst Eigeninitiative und Verantwortungsbewusstsein | Die Arbeit im Team sowie der Austausch mit verschiedensten Anspruchsgruppen bereiten dir Freude | Du kommunizierst stufengerecht und transparent | Setzt sich seit mehr als 180 Jahren für seine Mitglieder ein und bietet ihnen innovative Produkte und Dienstleistungen an | Branche: Sinnstiftendes Umfeld | Das Team von engagierten Expert:innen im Bereich Datenmanagement sucht Verstärkung | Moderner Arbeitsplatz im Raum Bern mit optimaler Anbindung an den öffentlichen Verkehr | Dank flacher Hierarchien findest du ein Umfeld mit raschen Entscheidungswegen - du kannst etwas bewegen! | Im persönlichen Gespräch geben wir dir gerne viele weitere Informationen! | Teilzeitmodelle werden unterstützt | Work Smart: Arbeiten von zu Hause und auf dem Arbeitsweg | Weiterbildung wird mit einem jährlichen Budget unterstützt und gefördert | Es erwartet dich ein offenes, familiäres und kollegiales Arbeitsklima | Erfolge werden gemeinsam gefeiert | Du übernimmst Verantwortung in spannenden Vorhaben",no skills found on this job ad,Data Scientist
302,Data Modeling & Metadata Specialist Banking,Pro Informatik AG,Zürich,"Data modelling for application re-wiring and migration onto a data lake | Capture and model data requirements, data definitions, business rules, data quality requirements and logical data models for a global data platform | Conduct impact assessments by analyzing and mapping as-is versus to-be data entities | Develop logical and physical data models following best practices to ensure high data quality and minimize redundancy | Partner with the Chief Data Office and business stakeholders to align data entities with the enterprise data catalog | Collaborate with development teams to implement data strategies, design data flows, and support the creation of conceptual data models","Several years of experience in data modelling and engineering within the banking sector | Knowledge of reference architectures, especially concerning integrated, data-driven landscapes and solutions | Solid knowledge around financial data classification and sensitivity | Expert knowledge of metadata management and related tools (Informatica MDM) | Strong understanding of data modeling standards, processes and tools (erwin Data Modeler, IBM InfoSphere Data Architect, Collibra / Informatica EDC or similar) | Fluent in English",Data Scientist
303,Data Quality / Back-Office Support 80-100% (befristet auf 2 Jahre),Wascosa AG,Luzern,Verantwortung für die strukturierte Ablage im Archivsystem | Prüfung und kontinuierliche Verbesserung von Daten im Archivsystem | Sicherstellung der Datenqualität | Pflege und Aktualisierung vorhandener Datensätze | Unterstützung bei der Organisation und Verwaltung der Archivdokumentation | Radsatz-/Datensatzkontrolle und Vervollständigung,"Abgeschlossene kaufmännische Ausbildung | MS-Office Anwenderkenntnisse und erste Erfahrung in gängigen ERP-Systemen | Sehr gute Deutschkenntnisse und gute Englischkenntnisse | Selbständige, präzise Arbeitsweise und gutes Organisationsvermögen",Data Scientist
304,Datenanalyst/in,Ärztekasse Genossenschaft,Urdorf,"Sie erstellen, erweitern und aktualisieren regelmässige Reports und Ad-hoc-Auswertungen für interne und externe Kundinnen und Kunden. Mit Ihren Programmier-kenntnissen sind Sie für den Datenfluss aus dem Data Warehouse verantwortlich und realisieren auch Automatisierungs- und Effizienzsteigerungspotentiale. | Sie sind verantwortlich für die Aufbereitung und Plausibilisierung unserer BI-Produkte und Analysen sowie für die Sicherstellung der Datenqualität. | Sie entwickeln unsere BI-Produkte weiter. | Sie unterstützen Kundinnen und Kunden bei der Analyse ihrer Geschäftsdaten und arbeiten aktiv im Controlling mit.","Sie besitzen einen Studienabschluss in Mathematik, Informatik, Informations-management, Naturwissenschaften, Statistik oder Wirtschaftswissenschaften mit mathematischem bzw. statistischem Schwerpunkt. Sie programmieren komfortabel in SQL und bringen fundierte Kenntnisse in Datenanalyse-Tools (z.B. R) und Datenvisualisierung (z.B. Power BI) mit. | Sie verfügen über mindestens drei Jahre Berufserfahrung in der Datenanalyse. | Sie besitzen ein ausgeprägt analytisches und konzeptionelles Denken, welches von einer systematischen Arbeitsweise begleitet ist. | Motivation und Eigenantrieb sind für Sie selbstverständlich. Sie sind neugierig und leben eine „Can-Do“-Attitude sowie eine proaktive, kundenorientierte Denk- und Handlungsweise. | Sie beherrschen stilsicheres Deutsch und arbeiten sicher in englischer Sprache; Kenntnisse in Französisch oder Italienisch sind von Vorteil.",Data Scientist
305,Senior Data & Analytics Engineer 80%-100% (H/F),CIGES SA,Boudevilliers,"Concevoir, développer et optimiser les pipelines de données (ETL/ELT) en assurant leur robustesse et leur performance. | Travailler en étroite collaboration avec les responsables d’application et les business analystes pour assurer la disponibilité et la cohérence des données en vue de répondre aux besoins métiers et analytiques | Assurer le maintien en condition opérationnelle des pipelines de données et participer à la résolution d’incidents | Appliquer les bonnes pratiques en matière de data engineering, de modélisation de données et de gouvernance de données | Documenter les pipelines, les modèles de données et les processus pour assurer la conformité et la bonne gouvernance des actifs de données. | Effectuer une veille continue sur les nouvelles technologies, outils et bonnes pratiques en data engineering et être force de proposition en vue de l’optimisation de la plateforme Data","Vous êtes d’une nature sereine, bienveillante et vous aimez le travail collaboratif | Orienté·e service vous faites preuve d’aisance à communiquer par oral et par écrit | Vous avez au minimum 5 ans d’expérience dans l’implémentation de pipelines de données | Expérience avérée de mise en œuvre de projets d’informatique décisionnelle | Connaissances de méthodes et outils d’orchestration de pipelines, de monitoring et de gestion de logs | Expériences dans le DataOps, le test de pipelines, l’historisation et la visualisation de données, la documentation et catalogue des données et CI/CD pour les pipelines sont un avantage | Intérêt dans l’analyse prédictive (Python ou R) est un plus | Formation universitaire, HES ou jugée équivalente | Français niveau C1",Data Scientist
306,Data Analyst de données de consommations énergétiques de bâtiments 80-100%,Signa-Terre SA,Genève,"Relèves et enregistrements des consommations auprès des fournisseurs d’énergie, des régies et/ou des propriétaires (internet, e-mail, chez le client) | Suivi des demandes et relance | Contrôle de la cohérence des données et de la qualité des relevés de consommations | Etablissement des Bilan énergétique (ImmoLabel) | Appui administratif aux gestionnaires clients",CFC employé.e de commerce ou équivalent | Une expérience dans le secteur de l’immobilier et/ou de la comptabilité est un atout | Très bonne connaissance des outils courants de MS Office et plaisir de traiter les chiffres | Personnalité avec une approche innovante et avec un fort esprit d’équipe | Méthodes de travail analytique et indépendante | Engagement et volonté d’apprendre | Expérience et aisance pour le contact téléphonique et écrit avec la clientèle | Solides compétences en communication | L’allemand et/ou l'anglais sont un atout,Data Scientist
309,ESG Data Specialist,Pensimo Management AG,Zürich,"Erfassung von ESG-Kennzahlen (Erfassung, Qualitätskontrolle, Optimierung des Abdeckungsgrads) | Weiterentwicklung einer umfassenden «Nachhaltigkeitsdatenbank» in Zusammenarbeit mit dem Data Manager | Aufbereitung von ESG-Kennzahlen für Berichterstattung und Benchmarking | Analyse von ESG-Kennzahlen und Identifikation von Optimierungspotential | Unterstützung bei der Umsetzung von Verbesserungsmassnahmen sowie bei interner und externer Schulung und Kommunikation zum Thema Nachhaltigkeit | Hochschulabschluss BSc oder MSc (Universität, ETH oder FH) in Architektur, Bau-, Ingenieur-, Wirtschafts- oder Umweltnaturwissenschaften | Zusatzausbildung in nachhaltiger Entwicklung oder Immobilienmanagement von Vorteil | Solides Grundwissen zu Nachhaltigkeit in Immobilien, Immobilienanlagen und Finanzprodukten | Erste Erfahrungen im Projektmanagement sowie in der Nutzung von Daten und Metriken zur Definition und Umsetzung von Initiativen zur Prozessverbesserung | Sehr gute Kenntnisse in MS Office 365, sichere Anwendung von Datenbanken und Content-Service-Plattformen | Sehr gute Deutschkenntnisse, gute Französisch- und Englischkenntnisse | Analytische Arbeitsweise und hohe Datenaffinität | Hoher Grad an Selbständigkeit, Eigenverantwortung und vernetztes Denken | Freude an neuen Fragestellungen und Herausforderungen | Ein wertschätzendes, kollegiales Arbeitsumfeld mit viel Vertrauen und Eigenverantwortung | Moderne Büros in Zürich (Kreis 5) und flexible Arbeitsmöglichkeiten inkl. Remote-Work | Attraktive Anstellungsbedingungen und Weiterentwicklungsmöglichkeiten | Ein Team, das gemeinsam weiterdenkt, Verantwortung übernimmt und Neues wagt",no skills found on this job ad,Data Scientist
312,Data Scientist,SonarSource SA,Geneva,"Implementierung wiederkehrender PLG-Analysen, einschließlich der Definition der wichtigsten Metriken im Zusammenhang mit dem Kundenerfolg und der Entwicklung entsprechender Tools (z. B. Dashboards) für die regelmäßige Überwachung. | Analyse des Nutzerverhaltens, um zu verstehen, wie sie sich anmelden, Funktionen nutzen und warum sie bleiben oder gehen. | Identifikation der Hauptchancenbereiche (z. B. Punkte, an denen neue Nutzer abspringen). | Verwendung von SQL und Python zur Arbeit mit Datensätzen aus unserem Produkt. | Erstellung und Verwaltung von Dashboards in Tableau zur Verfolgung wichtiger Metriken für das Team. | Nutzung von Produktanalyse-Tools, um Möglichkeiten zur Produktverbesserung zu finden. | Teilen der aus den Daten gewonnenen Erkenntnisse mit dem Team, um bessere Entscheidungen zu ermöglichen.","Mehr als 5 Jahre Erfahrung als Datenwissenschaftler | Vorherige Erfahrung im PLG bevorzugt | Starke SQL- und Python-Kenntnisse für Datenanalysen (einschließlich Bibliotheken wie Pandas und NumPy). | Erfahrung mit Produktanalysemethoden wie Funnel- und Kohortenanalyse. | Vertrautheit mit Produktanalyse-Tools (z. B. Amplitude, Mixpanel, Heap). | Erfahrung im Erstellen von Dashboards in Tableau oder einem ähnlichen Visualisierungstool. | Gute Kommunikationsfähigkeiten und die Fähigkeit, Daten klar für unterschiedliche Zielgruppen zu erklären. | Neugier und Interesse daran, wie Daten einem Produkt zum Erfolg verhelfen können.",Data Scientist
313,Senior Data Scientist,Elca informatique SA,Zurich,"Entwicklung und Implementierung innovativer AI, ML und Data Science Lösungen für unsere Kunden | Beratung unserer Kunden und Durchführung von Workshops zur Entwicklung von Anwendungsfällen und nachhaltigen Lösungen | Mitarbeit an der Angebotserstellung: Für Proof of Concepts (PoCs) und kleinere Projekte hast Du die Möglichkeit Verantwortung für die Angebotserstellung zu übernehmen. Bei grösseren Angeboten bist du als AI-Experte oder Expertin Teil eines Teams | Unterstützung im Pre-Sales-Bereich, Präsentationen bei Kunden und an Konferenzen/Events, inklusive Networking und Follow-Ups | Enge Zusammenarbeit mit Data Scientists, Data Engineers, IT-Architekten und Business Analysten; sowohl in Kundenteams als auch bei ELCA | Coaching und Mentoring von Teammitgliedern und Betreuung von Praktikantinnen und Praktikanten in spannenden, explorativen Projekten","Ein dynamisches Arbeitsumfeld mit einem jungen und hochmotivierten Team | Vielfältige Möglichkeiten, Dein Wissen und Deine Erfahrung durch die Arbeit an einer breiten Palette an spannenden Projekten, Kunden und Technologien zu erweitern | Attraktive Perspektiven für Karriere und persönliche Entwicklung durch Training und Coaching | Eine flache Hierarchie und eine Kultur der Zusammenarbeit über alle Disziplinen hinweg | Die Chance, durch den Aufbau grossartiger Software etwas im Leben der Menschen zu verändern | Attraktive Perspektiven für die weitere berufliche und persönliche Entwicklung mit verschiedenen internen Karrierepfaden | Work-Life-Balance (41 Std/W in Gleitzeit, Möglichkeit für Homeoffice, mind. 25 Ferientage), ergonomischer und flexibler Arbeitsplatz in einem multikulturellen Umfeld | Interessante Benefits wie z.B.: Beitrag an bestehendes Mobiltelefon oder Business Handy, 1/2- Tax Abonnement und geschäftlich unterwegs im Zug mit 1. Klasse, attraktive Pensionskassenmodelle, Übernahme der NBU (privat, weltweit), fortschrittliche Kranktaggeldversicherung sowie Flottenrabatt",Data Scientist
314,"Data Analytics Consultant (Zurich, Switzerland)",D ONE Value Creation AG,Zürich,Anforderungsanalyse und Lösungsdesign. | Datenmodellierung; Architekturdesign; Datenextraktion und -transformation. | Datenvisualisierung und Reporting. | Implementierung von Machine-Learning-Modellen. | Präsentation Ihrer Ergebnisse vor dem mittleren und oberen Management.,"Fachkenntnisse in mindestens einer Branche. | Pragmatische, ergebnisorientierte Einstellung bei der Beratung Ihrer Kunden. | Erfahrung im Umgang mit großen Datensätzen und Datenbanken. | Kenntnisse in relevanten Technologien und Programmiersprachen (z.B. SQL, Python, Hadoop, Spark, Tableau, Microsoft BI). | Ausgezeichnete Kommunikationsfähigkeiten in Deutsch und Englisch.",Data Scientist
316,(Senior) Data Science & Data Analytics Consultant 60-100%,Eraneos Switzerland AG,Zurich,"Beratung des Kunden zu Themen rund um Data & AI, Verstehen der Herausforderungen des Kunden und Ableiten von passenden Lösungsvorschlägen. | Durchführung von Kundenprojekten in verschieden Rollen. | Unterstützung in der Akquise von neuen Projekten. | du es liebst, Probleme zu lösen und du helfen möchtest, die Herausforderungen unserer Kunden mit den passendsten Mitteln anzugehen. | du in Data Science- und Data Analytics-Themen, -Methoden und -Tools fit bist und über Implementierungs-Erfahrung verfügst, beispielsweise in Python, SQL, Polars, PyTorch, Tensorflow, dbt. | du eine kommunikative Persönlichkeit bist und du Spass daran hast, mit Kolleginnen und Kollegen und verschiedenen Kunden zusammenzuarbeiten. | du auch Erfahrungen rund um die Inbetriebnahme von Lösungen mitbringst und du Tools wie MLflow und Airflow kennst. | du bereits über praktische Beratungs- und Projekterfahrung verfügst auch ausserhalb der Forschung und du eine praktische, ergebnisorientierte Mentalität hast. | du über einen ETH- oder Uni-Masterabschluss in einer quantitativen Disziplin verfügst, wie z.B. Data Science, Mathematik, Physik, Maschinenbau, Elektrotechnik oder Informatik. | deine Deutsch- oder Französisch-Kenntnisse verhandlungssicher sind und du Englisch sprichst. | Hüseyin als deine Ansprechperson freut sich auf deine Direktbewerbung über unsere Webseite (Lebenslauf, Diplome und Arbeitszeugnisse in PDF).","Erfahrungen im Cloud-Umfeld, eventuell gar Cloud-Zertifizierungen für Azure, AWS oder GCP. | Erfahrung im Umgang mit Snowflake und Databricks. | Ein gewisses Flair für «Hacking» und keine Angst vor der Kommandozeile.",Data Scientist
319,Data Analytics (Senior) Consultant - Deal Advisory,Students.ch,Zürich,"Arbeitsort Zürich | Unternehmen KPMG | Kategorie Absolventenstelle | Führen Sie vielfältige Strategieprojekte während Deals für internationale Unternehmen durch | Tragen Sie zu Wachstumsstrategien, Markteintrittsanalysen und strategischen Transformationen bei | Entwickeln Sie nachhaltige Konzepte zur Wertsteigerung unter Nutzung von Datenanalysen zur EBITDA-Verbesserung | Nutzen Sie modernste Tools wie Alteryx, Tableau, Power BI, um das Potenzial zur Wertsteigerung zu quantifizieren | Gestalten Sie die Zukunft, indem Sie herausfordernde analytische Probleme mit Big Data angehen. | Präsentieren Sie datenbasierte Erkenntnisse und strategische Lösungen vor leitenden Stakeholdern und Kunden","Berufserfahrung in der Beratung oder im M&A-Bereich (1-2 Jahre für Consultant, 2-4 Jahre für Senior Consultant) | Starke technische Fähigkeiten in Alteryx, PowerBi oder Tableau, MS Excel, Python-Kenntnisse sind von Vorteil | Bachelor- oder Masterabschluss in Wirtschaftswissenschaften, Computertechnik, Wirtschaftsinformatik oder einem vergleichbaren Bereich mit Schwerpunkt Strategie oder Datenanalyse | Starke analytische und quantitative Problemlösungsfähigkeiten mit hoher geistiger Flexibilität und außergewöhnlichem Interesse an komplexer Datenanalyse (z. B. räumliche und prädiktive Analysen) und Datenvisualisierungen | Fähigkeit, unter Druck zu bestehen, Herausforderungen professionell zu übernehmen und überdurchschnittliche Ergebnisse innerhalb enger Fristen zu liefern. | Starke Kommunikationsfähigkeiten in Englisch sind erforderlich, Deutsch- und/oder Französischkenntnisse sind von Vorteil",Data Scientist
320,Data Analyst,Banque Lombard Odier & Cie SA,Geneva,"Sammeln und Konsolidieren von Daten aus internen Systemen (Finanzen, Personal, Beschaffung, Projektmanagement) über APIs oder direkte Extraktion | Entwicklung und Pflege analytischer Modelle und Dashboards mit Tools wie Excel, Power BI, Tableau und anderen",Analyse und Verbesserung operativer Prozesse im Bereich IT Development | Erstellung von Tools und Prototypen zur Straffung administrativer Arbeitsabläufe,Data Scientist
321,Data Scientist Intern,"G. et F. Châtelain, succursale de Chanel SARL",Geneva,"Entwicklung, Start und Automatisierung robuster und leistungsfähiger Datenpipelines | Mitwirkung bei der Entwicklung von Machine Learning-Lösungen für konkrete geschäftliche Fragestellungen | Durchführung statistischer Analysen und Interpretation der Ergebnisse zur Unterstützung der Entscheidungsfindung | Klare und zielgruppengerechte Kommunikation Ihrer Ergebnisse (technisch und nicht-technisch) | Beitrag zu bereichsübergreifenden Projekten in Supply Chain, Operations und Produktion","Masterstudent/in in Data Science, Informatik, Ingenieurwesen, Mathematik oder einem ähnlichen Bereich | Fließende Beherrschung von Französisch und Englisch, mündlich und schriftlich | Fundierte Erfahrung mit Python und SQL; Interesse an Cloud-Tools (Azure, GCP, …) ist von Vorteil | Neugier, Genauigkeit, Teamgeist und Serviceorientierung | Pflichtpraktikumsvereinbarung erforderlich",Data Scientist
322,"Talent Community - Data, Analytics & Technology",Wüest Partner,Zurich,"Universitätsabschluss (Bachelor, Master, PhD) mit analytischem oder statistischem Hintergrund / in Naturwissenschaften oder Ingenieurwesen | Interesse an immobilienbezogenen Themen und Datenanalytik, Technologien wie Machine Learning, Künstliche Intelligenz und Big Data | Digitale Affinität, starke Kommunikationsfähigkeiten (fließend in Englisch und Deutsch)","Attraktive Anstellungsbedingungen mit variablem Vergütungsbestandteil | Flexibles Work Smart-Konzept mit Homeoffice-Möglichkeiten | Professionelle und kollegiale Unternehmenskultur mit großartigen Events (Firmenfeiern, Croissant-Pausen etc.) | Hoher Teamgeist, flache Hierarchien und abwechslungsreiche Aufgaben | Moderne Büros in den Zentren von Zürich, Bern, Lugano oder Genf | Großzügiges Weiterbildungsbudget inklusive Zeit dafür sowie weitere attraktive Sozialleistungen",Data Scientist
323,Data Scientist (m/w/d),Sympany,Basel,"Erstellen und Validieren von statistischen und multivariaten Analysen und Modellen unter Anwendung von Data Science Methoden | Identifizieren von Mustern und Trends zur Prognoseerstellung und zur Unterstützung von strategischen Entscheidungen | Selbständiges Aufbereiten von Daten mit R oder Phyton | Mitarbeiten in Projekten sowie Sicherstellen des fachbereichsübergreifenden Stakeholdermanagements (z.B. Data Intelligence, Aktuariat, Controlling) | Aufbauen und Pflegen von Data-Pipelines sowie Erstellen von Datenvisualisierungen für interne Stakeholder | Sicherstellen der einheitlichen Methodiknutzung und Einhaltung von Datenschutz-Anforderungen | Weiterentwickeln von Predictive Analytics, Machine Learning und KI-Anwendungen | Sie verfügen über einen Masterabschluss in einem Studiengang mit quantitativem Schwerpunkt wie Mathematik, Physik, Statistik, Data Science oder ähnlichem. | Sie bringen fundierte Kenntnisse sowie mehrjährige Berufserfahrung in Data Science und Machine Learning mit. | Sie sind mit R/Phyton und DWH bestens vertraut, idealerweise konnten Sie auch Ihre SQL-Kenntnisse bereits in der Praxis vertiefen. | Sie überzeugen als kundenorientierter Teamplayer und tauchen gerne in neue Themen ein. | Sie arbeiten sehr strukturiert und haben Spass an der selbständigen Arbeit im Alltag. | Sie können adressatengerecht kommunizieren und Bedürfnisse sowie Ziele lösungsorientiert und fokussiert umsetzen. | Sie bringen fliessende Deutschkenntnisse in Wort und Schrift mit, Ihre guten Englischkenntnisse runden Ihr Profil ab. | Übernahme der Beiträge an die Krankentaggeldversicherung und Nichtbetriebsunfallversicherung sowie von 2/3 des BVG-Beitrages | Weltweit 1. Klasse versichert bei Unfall | Treuebonus ab 5 Jahren und Beteiligung am Unternehmenserfolg auf allen Stufen (bei Festanstellung)","Vergünstigungen auf Sympany Produkte, z.B. 50% auf die Grundversicherung und Rabatte auf diverse Angebote z. B. im Bereich Mobilität oder Multimedia | Vergünstigtes Essen im eigenen Restaurant | Beteiligung an den Kosten des öffentlichen Verkehrs (Jobticket)",Data Scientist
324,Senior Data Scientist & Product Owner,Swiss Medical Network,Echandens,"Master- oder Doktorabschluss in Informatik, Statistik, Mathematik oder einem verwandten Bereich.","Mindestens 5 Jahre Berufserfahrung im Bereich Data Science, vorzugsweise im Gesundheitswesen mit Erfahrung im Krankenhausbereich ist von Vorteil.",Data Scientist
325,Senior AI Engineer,Elca informatique SA,Pully,"Umsetzung von End-to-End Data-Science- und KI/ML-Projekten von der Anforderung bis zur Auslieferung | Analyse und Modellierung von Daten sowie Bewertung und Kommunikation der Ergebnisse an verschiedene Stakeholder | Modellierung komplexer Geschäftsprobleme mit maschinellem Lernen: Sie wählen geeignete Methoden und Modelle aus, passen diese an Kundendaten an und optimieren sie bei Bedarf | Erstellung von Prozessen und Datenpipelines zur Vorbereitung von Rohdaten für das Modelltraining und die Inferenz | Erstellung, Pflege und Optimierung von MLOps-Pipelines zur Automatisierung von Modelltraining, -bereitstellung und -überwachung | Enge Zusammenarbeit mit interdisziplinären IT- und Engineering-Teams | Weitergabe von technischem Know-how und Betreuung von Junior Data Scientists.
Ein Abschluss einer technischen Universität | Ein Abschluss einer technischen Universität","Mindestens 5 Jahre Erfahrung im KI-Bereich als Data Scientist, ML Engineer oder in einer ähnlichen Position | Ein technisches Hochschulstudium | Fundierte Kenntnisse in Python oder anderen Programmiersprachen. Erfahrung mit Data-Science- und Machine-Learning-Frameworks (z. B. scikit-learn, TensorFlow, PyTorch), Datenanalysetools (z. B. pandas) und MLOps-Tools (z. B. MLflow) | Fundierte Kenntnisse in Windows, Linux, Netzwerktechnik, Datenspeicherung, Webservices sowie Softwareentwicklung und Kollaborationstools (z. B. Git, JIRA, Microsoft Teams) | Kenntnisse in Cloud-Technologien (Azure, AWS, Google Cloud) und Big-Data-Plattformen (z. B. Spark, Databricks) sind von Vorteil | Starke analytische und problemlösende Fähigkeiten. | Flexibilität für Reisen in der Romandie | Gute Kommunikationsfähigkeiten, Fähigkeit zur Pflege und zum Aufbau von Kundenbeziehungen | Fließend in Französisch und Englisch",Data Scientist
326,Medical Data Scientist / Statistician (Full time - Remote Europe),Ikerian AG,Bern,"Zusammenarbeit mit den Teams für Real-World Evidence (RWE), Datenstrategie und Vertrieb bei der Erstellung und Lieferung von Datenspezifikationen für Forschungsprojekte. | Zusammenarbeit mit dem Engineering- und Machine-Learning-Team zur Pflege und Verbesserung der Datenplattform, die Daten erfasst und standardisiert. | Bereitstellung von Informatik-Expertise für das Datenstrategie- und Vertriebsteam zur Unterstützung der Interaktionen mit Datenpartnern. | Teilnahme an der Überprüfung der Qualität eingehender Daten, Fehlerbehebung und Problemlösung, um sicherzustellen, dass die Daten den Anforderungen des RWE-Teams entsprechen. | Mitwirkung bei der Verwaltung und Verbesserung unseres gemeinsamen Datenmodells. | Mit klinischem Wissen an der Gestaltung und Pflege eines automatisierten Prozesses zur Datenqualitätsprüfung teilnehmen.","Masterabschluss in Statistik, Biostatistik, Data Science oder einem verwandten Bereich. | PhD/MBA von Vorteil | Ausgezeichnete mündliche und schriftliche Englischkenntnisse. | Wohnsitz in einem europäischen Land | Mindestens 3 Jahre relevante Berufserfahrung in biostatistischen Projekten. | Mindestens 3 Jahre Erfahrung im Gesundheitswesen oder in pharmazeutischen Bereichen. | Nachgewiesene Erfahrung in statistischer Analyse und Data Science, vorzugsweise in klinischer Forschung oder Gesundheitswesen. | Starke Kenntnisse in Python und/oder R für Datenanalyse und statistische Modellierung. | Erfahrung mit Git, Softwareentwicklung. | Erfahrung in der Analyse medizinischer Datensätze sowie Vertrautheit mit Real-World Evidence und Ophthalmologie ist von Vorteil. | Starke Kommunikations- und Teamfähigkeiten, besonders in multidisziplinären Teams. | Erfahrung in Startups oder Beratungsumgebungen ist ein Plus. | Nachgewiesene unternehmerische und kooperative Denkweise. | Kenntnisse der besten Praktiken in Biostatistik und klinischen Studien. | Starke analytische und problemlösende Fähigkeiten, ein Auge fürs Detail. | Fähigkeit, selbstständig und im Team zu arbeiten. | Verfügbarkeit zur Arbeit während der Geschäftszeiten der Mitteleuropäischen Zeit (MEZ).",Data Scientist
328,Chief Data Officer,Banque Lombard Odier & Cie SA,Geneva,"Datenstrategie & Governance: Definition und Implementierung des Daten-Governance-Rahmens der Bank, Sicherstellung der Einhaltung regulatorischer Anforderungen und interner Richtlinien. | Datenarchitektur: Entwurf und Überwachung der unternehmensweiten Datenarchitektur, Gewährleistung von Skalierbarkeit, Sicherheit und Ausrichtung an den Geschäftsanforderungen. | Datenintegration: Leitung von Initiativen zur Integration von Daten aus verschiedenen internen und externen Quellen, Sicherstellung hoher Datenqualität und Konsistenz. | Analytik & Visualisierung: Förderung der Nutzung von Datenvisualisierung und Self-Service-Analytics-Tools zur Befähigung der Geschäftsbenutzer und Verbesserung der Entscheidungsfindung. | KI & Maschinelles Lernen: Vorantreiben der Einführung von KI/ML-Technologien, vom Proof-of-Concept bis zur Produktion, in Zusammenarbeit mit Data Scientists und Geschäftseinheiten. | Teamführung: Leitung und Mentoring eines Teams von Datenfachleuten (Data Engineers, Data Scientists, Analysten), Förderung einer Kultur der Innovation, Zusammenarbeit und kontinuierlichen Lernens. | Stakeholder-Engagement: Vertrauenswürdiger Berater des Senior Managements in allen datenbezogenen Angelegenheiten und Vertretung des Data Office in strategischen Initiativen. | Daten-Governance und regulatorischer Compliance (z. B. FINMA, DSGVO) | Entwurf und Implementierung von Datenarchitekturen (cloud-native, Data Mesh und moderne Datenplattformen) | Datenintegrationswerkzeugen und ETL-Prozessen | Business-Intelligence-Plattformen (z. B. Power BI, Tableau, Qlik) | KI/ML-Frameworks und Data-Science-Methodologien","Master-Abschluss in Informatik, Data Science, Ingenieurwesen oder einem verwandten Bereich. | Mehr als 10 Jahre Erfahrung in Datenmanagement-Rollen, davon mindestens 3 Jahre in einer Führungsposition. | Nachgewiesene Erfahrung in:
Daten-Governance und regulatorischer Compliance (z. B. FINMA, DSGVO)
Entwurf und Implementierung von Datenarchitekturen (cloud-native, Data Mesh und moderne Datenplattformen)
Datenintegrationswerkzeugen und ETL-Prozessen
Business-Intelligence-Plattformen (z. B. Power BI, Tableau, Qlik)
KI/ML-Frameworks und Data-Science-Methodologien | Daten-Governance und regulatorischer Compliance (z. B. FINMA, DSGVO) | Entwurf und Implementierung von Datenarchitekturen (cloud-native, Data Mesh und moderne Datenplattformen) | Datenintegrationswerkzeugen und ETL-Prozessen | Business-Intelligence-Plattformen (z. B. Power BI, Tableau, Qlik) | KI/ML-Frameworks und Data-Science-Methodologien | Fundiertes Verständnis von Datenbereichen im Bank- und Finanzdienstleistungssektor. | Ausgezeichnete Kommunikations- und Stakeholder-Management-Fähigkeiten. | Fließend in Englisch und Französisch | Wohnsitz in der Schweiz oder Bereitschaft zum Umzug",Data Scientist
331,Working Student in GenAI/Software/Data Engineering (all genders) 50-100%,AXA Versicherungen AG,Winterthur,"Seien Sie Teil unseres Data & AI Claims Teams und entwickeln Sie gemeinsam mit anderen Ingenieuren und Data Scientists bestehende Anwendungsfälle weiter und unterstützen Sie die Umsetzung neuer. | Entwickeln, optimieren und betreiben Sie Python-basierte GenAI/ML-Anwendungen in Google Cloud. | Teilen Sie Ihr Wissen mit anderen Teammitgliedern und tragen Sie proaktiv zur Lösungsentwicklung unserer Anwendungen bei.","Praktische Erfahrung in Python und SQL. | Begeisterung für neue technische Entwicklungen und die Bereitschaft, sich in einem dynamischen Umfeld kontinuierlich weiterzuentwickeln. | Gute Englischkenntnisse.",Data Scientist
332,Working Student in Data Science (all genders) 50-100%,AXA Versicherungen AG,Winterthur,"Seien Sie Teil unseres Data & AI Claims Teams und entwickeln Sie gemeinsam mit anderen Data Scientists und Ingenieuren bestehende Anwendungsfälle weiter und unterstützen Sie die Umsetzung neuer. | Beteiligen Sie sich an der Entwicklung von Machine Learning-Lösungen, die auf spezifische geschäftliche Herausforderungen angewendet werden. | Führen Sie statistische Analysen durch und interpretieren Sie die Ergebnisse zur Unterstützung von Entscheidungsprozessen. | Teilen Sie Ihr Wissen mit anderen Teammitgliedern und tragen Sie proaktiv zur Verbesserung unserer Anwendungen bei.","Praktische Erfahrung in Python und SQL. | Begeisterung für neue technische Entwicklungen und die Bereitschaft, sich in einem dynamischen Umfeld kontinuierlich weiterzuentwickeln. | Gute Englischkenntnisse.",Data Scientist
334,Data Engineer (h/f) 80-100%,Groupe Mutuel,Martigny,"Tu conçois et implémentes l'infrastructure Cloud Data en lien avec les besoins de l'entreprise | En analysant les demandes métiers, tu proposes des idées concrètes et innovantes issues du monde de la Data | Tu participes aux choix technologiques et contribues à la mise en place d'environnements techniques robustes | Aux côtés des Data Scientists, tu accompagnes les réflexions et questionnes les nouveaux flux de données avec un regard critique | Tu veilles à la qualité, la sécurité et la cohérence des projets, tout en partageant tes compétences et en faisant évoluer les pratiques de l'équipe | Tu maîtrises Python, SQL et Spark/Databricks, et tu sais comment en tirer le meilleur pour faire parler les données | Tu es à l'aise avec Docker et Kubernetes, et tu sais les utiliser pour faire tourner des applications de manière fiable et efficace | Les concepts Big Data n'ont plus de secret pour toi, et tu les appliques avec rigueur et créativité | Tu incarnes les principes du Software Craftsmanship : code propre, maintenable, et souci du détail font partie de ton quotidien | Tu échanges facilement avec ton équipe, tu sais défendre tes idées tout en restant ouvert·e à la remise en question, aux feedbacks constructifs et à l'apprentissage continu - parce que progresser ensemble, c'est ce qui te motive | Tu disposes d'une formation professionnelle supérieure (EPF, HES) ou d'une
expérience jugée équivalente | Tu disposes d'une expérience professionnelle d'au moins cinq ans dans un poste similaire, ce qui te permet d'aborder les projets avec assurance et expertise | Tu maîtrises les pratiques DevSecOps, telles que l'intégration et le déploiement continus (CI/CD), l'utilisation de Git, ainsi que les principes desecurity by design, que tu appliques avec rigueur dans tes réalisations | Et si tu as déjà travaillé avec des technologies comme Azure, Terraform ou ElasticSearc, c'est la cerise sur le gâteau!",no skills found on this job ad,Data Scientist
338,Senior Projektmanager:in DATA & AI 80-100%,Eraneos Switzerland AG,Zurich,"Planung, Steuerung und Koordination von Data- & AI-Projekten entlang des gesamten Projektlebenszyklus – von der Ideation bis zum Rollout. | Übersetzung von Business-Anforderungen in technische Konzepte gemeinsam mit Data Scientists, Data Engineers und IT. | Sicherstellung von Zeit-, Budget- und Qualitätszielen sowie aktives Management von Risiken und Abhängigkeiten. | Stakeholder-Management in Fachbereichen wie Sales, Produktion, Supply Chain Management sowie auf Managementebene. | Beobachtung und Bewertung von Trends, Technologien und Best Practices im Bereich Künstliche Intelligenz, Data Analytics und Industrie 4.0.","Du mindestens 4 Jahre Erfahrung im Projektmanagement von Data- und/oder AI-Projekten mitbringst – idealerweise in der produzierenden Industrie oder Konsumgüterbranche. | Du über fundierte Kenntnisse in den Bereichen Data Management, Analytics, AI/ML und Agentic AI verfügst. | Du Erfahrung mit agilen Projektmanagement-Methoden (z. B. Scrum, SAFe, HERMES agil) has. | Du strukturiert, methodisch und überzeugend arbeitest und Kundenteams sicher durch IT- und Digitalisierungsprojekte führen kannst. | Du fliessende Deutsch- und Englischkenntnisse sowie sehr gute kommunikative Fähigkeiten mitbringst.",Data Scientist
339,"(Senior) Data Engineer (w/m/d), 80-100 %",Concordia,Luzern,"Architektur & Entwicklung von Datenplattformen: Planung und Umsetzung skalierbarer Lösungen mit Microsoft Azure / Fabric Komponenten wie Data Lake, Data Factory, Power BI oder Databricks. | ETL- und Datenverarbeitungsprozesse: Entwicklung, Optimierung und Wartung leistungsfähiger Datenpipelines. | Datenmodellierung: Aufbau robuster Datenmodelle sowie Performance-Optimierung für effiziente Abfragen. | Automatisierung & CI/CD: Umsetzung von CI/CD-Prozessen zur Automatisierung von Deployments und Tests. | Teamübergreifende Zusammenarbeit: Enge Abstimmung mit Data Scientists, den Fachbereichen und weiteren Stakeholdern zur gemeinsamen Entwicklung datengetriebener Lösungen. | Best Practices & Zukunftssicherheit: Sicherstellung der Nachhaltigkeit, Wartbarkeit und Skalierbarkeit unserer Datenplattform.","Du bringst mehrjährige Berufserfahrung als Data Engineer oder in einer vergleichbaren Rolle mit Schwerpunkt auf Microsoft Azure mit. | Du hast richtig Lust, auf der grünen Wiese zu starten und gemeinsam mit der Crew die Transformation erfolgreich zu gestalten. | Du kannst Datenpipelines skalierbar gestalten und Abfragen effizient optimieren. | Du hast Erfahrung in der Umsetzung und Pflege von CI/CD-Pipelines zur Automatisierung von Deployments und Tests und bist vertraut mit Tools wie GitHub. | Du hast fundierte Kenntnisse in Datenmodellierungsmethoden wie Star Schema, Snowflake und Data Vault. | Du möchtest klaren Business Value generieren und scheust dich auch nicht davor, beratend zu unterstützen. | Du bist teamorientiert und es macht dir Spass, dein Know-How deinen Kolleg:innen zu vermitteln. | Erfahrungen in Microsoft Fabric sind ein Plus.",Data Scientist
340,Cloud Data Engineer,Talan,Geneva,"Entwurf und Bereitstellung von cloud-nativen Datenarchitekturen (Azure Databricks, MS Fabric, Snowflake usw.) in Produktionsqualität. | Aufbau robuster ELT-Batch- und Streaming-Pipelines. | Automatisierung der Infrastruktur mit Terraform (IaC) und Implementierung von CI/CD-Praktiken. | Sicherstellung von Skalierbarkeit, Sicherheit (private Netzwerke, Governance) und Datenqualität (Qualität, Metadaten, gute Beobachtbarkeit). | Zusammenarbeit mit multidisziplinären Teams (ML-Ingenieure, Cloud-Architekten, Data Scientists) zum Aufbau widerstandsfähiger, industrialisierter und wertorientierter Infrastrukturen. | Weitergabe Ihrer Expertise: Definition von Standards und Kompetenzaufbau im Team.","Mehr als 5 Jahre Erfahrung im Data Engineering mit starkem Cloud-Bezug. | Selbstständigkeit, Ergebnisorientierung und ausgezeichnete Kommunikationsfähigkeiten. | Beherrschung von Python, SQL, Git. | Erfahrung mit Spark für die Datenverarbeitung. | Expertise in Datenqualitäts- und Metadatenmanagement-Tools. | Gute Kenntnisse in dbt und fortgeschrittener Datenmodellierung. | Kenntnisse in privaten und sicheren Netzwerken in Cloud-Umgebungen. | Fließendes Englisch.",Data Scientist
341,Cloud Data Platform Expert - Azure/Databricks,Elca informatique SA,Bern,"Du beteiligst Dich an mehreren Cloud Data Platform-Projekten sowie als zentrale Anlaufstelle für unsere Kunden | Du unterstützt die Akquisition neuer Kundenprojekte, indem Du Angebote vorbereitest und mit dem Kunden besprichst | Du bist mitverantwortlich für Design, Code und Konfiguration von Komponenten, die Data Ingestion, real-time Streaming, Batch Processing, Datenextraktion und Transformation über mehrere Datenquellen und Anwendungen hinweg verwalten | Du interagierst mit Engineering-Teams über Projekte hinweg und stellst sicher, dass Deine Lösungen die Kundenanforderungen in Bezug auf Funktionalität, Leistung, Verfügbarkeit, Skalierbarkeit, Sicherheit und Zuverlässigkeit erfüllen | Du bewertest Analytics-Architekturen und -Umgebungen und machst Verbesserungsvorschläge | Du coachst in innovativen Technologien und fungierst als Mentor unserer Teammitglieder","Chance Deine Fachkompetenz durch vielfältige Projekte und einzigartige Produkte, neueste Technologien und Kunden aus unterschiedlichsten Branchen zu erweitern | Attraktive Perspektiven durch stetige Schulung, Coaching und mit einem internen Karriereweg | Unsere Kultur macht den Unterschied! Wir leben aktiv flache Hierarchien und eine offene hilfsbereite Zusammenarbeit über alle Disziplinen und Abteilungen | Wir organisieren regelmässige Anlässe wie z.B. Brown Bag Lunches und Coding Events sowie gemütliche und sportliche ausserbetriebliche Zusammenkünfte | Gute Work-Life-Balance (Gleitzeit, Homeoffice), moderner und flexibler Arbeitsplatz in einem multikulturellen Umfeld | Top Benefits wie z.B.: Ferienkauf von bis zu 13 Tagen, Beitrag an privates Mobiltelefon oder Business Handy, Halbtax, geschäftlich unterwegs in 1. Klasse, flexible Pensionskassenmodelle, Übernahme KTG und NBU (privat, weltweit), und vieles mehr",Data Scientist
344,Data Platform Engineer (all genders),HolidayCheck AG,Bottighofen,"Besitze und entwickle unsere AWS-basierte Datenplattform, um kosteneffizient, leicht veränderbar, sicher im Design und anpassungsfähig an die sich schnell verändernde KI-Landschaft zu sein | Bewerte neue Datenanfragen schnell mit AWS Serverless und Open-Source-Alternativen | Baue und erweitere die Infrastruktur mit Terraform und migriere Legacy-Setups zu IaC | Unterstütze End-to-End-ML-Workflows, indem du Trainings-, Bereitstellungs- und Überwachungs-Pipelines vereinfachst | Reduziere die Komplexität zwischen Clouds und fördere eine effiziente Zusammenarbeit zwischen AWS- und GCP-Plattformen | Treibe betriebliche Exzellenz durch Überwachung, Alarmierung und resilientes Systemdesign voran — mit dem Vertrauen, Änderungen vorzunehmen, die die Kernbetriebsabläufe beeinflussen können","Unser Team ermöglicht sicheren und nahtlosen Zugang zu Daten, um Datenprodukte für HolidayCheck zu erstellen. Unsere Kunden sind Datenwissenschaftler, Business-Analysten und Produktverantwortliche. Wir berühren fast jedes Team bei HolidayCheck. | Wir sind ein internationales Team an mehreren Standorten in Mitteleuropa | Unsere Hauptprogrammiersprachen sind Python und Scala | Unser Tech-Stack umfasst, ist aber nicht beschränkt auf Airflow, Apache Spark/EMR, AWS, Docker/Kubernetes (EKS), DevOps (ArgoCD), Terraform, Kafka",Data Scientist
346,Senior Data Engineer,Zühlke Engineering AG,Schlieren,"Ob in der Cloud oder in einem lokalen Rechenzentrum, Sie navigieren fachkundig durch die Welt von Big Data und helfen unseren Kunden, ihre Daten geschäfts- oder betriebsbereit zu machen. | Sie greifen effizient und reproduzierbar auf vielfältige Datenquellen zu. | Sie entwerfen, testen und überwachen verteilte Datenverarbeitungspipelines. | Sie arbeiten eng mit Data Scientists bei der Erstellung von Machine-Learning-Modellen zusammen. | Sie führen Leistungs- und Kostenschätzungen für verschiedene Anwendungsfälle durch. | Sie entwickeln und erstellen aussagekräftige Dashboards zur Visualisierung verarbeiteter Daten.","Sie sind vertraut mit Big Data, massiv skalierbaren Datenbanken, Cloud-Infrastrukturen und verteilten Algorithmen. | Sie haben eine Leidenschaft für nachhaltige Softwareentwicklung und mehrere Jahre Erfahrung in technischen Rollen gesammelt. | Neben Ihrer Expertise in Python und SQL haben Sie idealerweise praktische Erfahrung oder starkes Interesse an Technologien wie Hadoop, Apache Spark, Hive, Airflow, RDBMS, NoSQL, DevOps, Kubernetes sowie Java oder .NET. | Sie verfügen über ein gutes Verständnis der Möglichkeiten großer öffentlicher Cloud-Umgebungen und haben möglicherweise Ressourcen von Amazon AWS, MS Azure oder Google GCP genutzt. | Sie besitzen einen Hochschulabschluss (ETH, Uni, FH) in Informatik, Mathematik oder einem ähnlichen Fachgebiet. | Fließende Deutsch- und Englischkenntnisse sind für diese Position erforderlich.",Data Scientist
350,Data Engineer Intern,VF International Sagl,Stabio,EU / EWR-Staatsbürgerschaft | Abschluss spätestens im November 2025 oder später,"Aufbau und Pflege skalierbarer Datenpipelines und Integrationen, um eine zeitnahe und zuverlässige Datenverfügbarkeit für Analysen und Berichte sicherzustellen. | Transformation und Bereinigung von Rohdaten aus verschiedenen Quellen in strukturierte Formate zur Unterstützung von Business Intelligence und maschinellen Lernanwendungen. | Überwachung und Optimierung von Datenabläufen und Speicherlösungen zur Verbesserung der Leistung, Senkung der Kosten und Sicherstellung der Datenqualität. | Zusammenarbeit mit funktionsübergreifenden Teams (z. B. Data Scientists, Analysten, Product Owner), um Datenanforderungen zu verstehen und umsetzbare Lösungen zu liefern. | Dokumentation und Pflege der Datenarchitektur, Prozesse und Best Practices zur Unterstützung des Wissensaustauschs und der Einarbeitung im Team. | Unterstützung weiterer Initiativen und Projekte im Global Data Engineering Team, Beitrag zu Innovation und kontinuierlicher Verbesserung.",Data Scientist
352,Senior Data Engineer,Abbott AG,Switzerland &gt; Basel : H-127 A2,"Entwicklung von Datenpipelines und Integration:
Aufbau, Pflege und Optimierung von End-to-End-Datenpipelines, die Daten aus mehreren Quellen erfassen, einlesen und verarbeiten, um die Verfügbarkeit und Zugänglichkeit der Daten für AA-Initiativen sicherzustellen.
Zusammenarbeit mit Geschäftsverantwortlichen und Fachexperten zur Modellierung von Datenlandschaften, Sicherung von Datenaustausch und Implementierung effektiver Datenintegrationsstrategien. | Aufbau, Pflege und Optimierung von End-to-End-Datenpipelines, die Daten aus mehreren Quellen erfassen, einlesen und verarbeiten, um die Verfügbarkeit und Zugänglichkeit der Daten für AA-Initiativen sicherzustellen. | Zusammenarbeit mit Geschäftsverantwortlichen und Fachexperten zur Modellierung von Datenlandschaften, Sicherung von Datenaustausch und Implementierung effektiver Datenintegrationsstrategien. | Entwurf und Verwaltung von Datenumgebungen in der Cloud mit Schwerpunkt auf AWS, mit starkem Fokus auf Skalierbarkeit, Leistung und Sicherheit. | Nutzung verteilter Verarbeitungs-Frameworks (z. B. Apache Spark, Hadoop, Amazon Glue) und verschiedener Datenbanktechnologien (z. B. traditionelle RDBMS, NoSQL, MPP) zum Aufbau einer robusten Dateninfrastruktur für die Advanced Analytics der EPD. | Enge Zusammenarbeit mit Data Scientists, Engineers und IT zur Kuratierung, Aufbereitung und Vorbereitung von Daten für fortgeschrittene analytische Modelle. | Mitwirkung bei der Ableitung und kontinuierlichen Verfeinerung von AA-Richtlinien und Standards durch Synthese von Erkenntnissen aus priorisierten Initiativen („learning while doing and driving impact“). | Sicherstellung der Einhaltung von Daten- und Datenschutzstandards unter Berücksichtigung eines fundierten Verständnisses von Informationssicherheitsprinzipien. | Technische Führung und Mentoring von Junior Data Engineers, Förderung eines kollaborativen Umfelds, das die Lücke zwischen Geschäftsanforderungen und technischer Umsetzung schließt. | Auf dem Laufenden bleiben über neue Daten-Technologien und -Methoden und Integration innovativer Praktiken in die AA-Initiativen der EPD.","Datenarchitektur & Cloud-Umgebungen:
Entwurf und Verwaltung von Datenumgebungen in der Cloud mit Schwerpunkt auf AWS, mit starkem Fokus auf Skalierbarkeit, Leistung und Sicherheit.
Nutzung verteilter Verarbeitungs-Frameworks (z. B. Apache Spark, Hadoop, Amazon Glue) und verschiedener Datenbanktechnologien (z. B. traditionelle RDBMS, NoSQL, MPP) zum Aufbau einer robusten Dateninfrastruktur für die Advanced Analytics der EPD. | Entwurf und Verwaltung von Datenumgebungen in der Cloud mit Schwerpunkt auf AWS, mit starkem Fokus auf Skalierbarkeit, Leistung und Sicherheit. | Nutzung verteilter Verarbeitungs-Frameworks (z. B. Apache Spark, Hadoop, Amazon Glue) und verschiedener Datenbanktechnologien (z. B. traditionelle RDBMS, NoSQL, MPP) zum Aufbau einer robusten Dateninfrastruktur für die Advanced Analytics der EPD.",Data Scientist
357,Product Owner - Advanced Analytics for Commercial Domain,Abbott AG,Allschwil,"Zusammenarbeit mit Geschäftseinheiten, Data Scientists und anderen Stakeholdern, um ein umfassendes Verständnis von Herausforderungen und Chancen zu gewinnen. | Leitung der vollständigen Problemdefinition und Empfehlung wirkungsvoller Machine Learning-, KI- oder GenKI-Lösungen mit Schwerpunkt auf deren Integration für maximale Effektivität. | Entwicklung und Umsetzung strategischer Kommunikations- und Engagementpläne zur Förderung von Bewusstsein, Verständnis und Akzeptanz von Advanced Analytics-Initiativen in der globalen EPD-Community in Abstimmung mit dem direkten Vorgesetzten. | Förderung der Entwicklung wesentlicher Fähigkeiten, um unsere Belegschaft zu befähigen, die datengetriebene Kultur anzunehmen. | Identifikation und Verknüpfung von Machine Learning-, KI- und GenKI-Möglichkeiten mit strategischen EPD-Prioritäten und Geschäftskennzahlen. | Unterstützung bei der Definition des Budgets und der Ressourcen für die Durchführung eines AA/AI-Projekts in Zusammenarbeit mit dem AA-Team und den Geschäfts-Stakeholdern. | Sicherstellung der Akzeptanz von Advanced Analytical Lösungen. | Verantwortung für Produktvision, Projektmanagement und Sprint-Umsetzung. | Förderung der Einhaltung von Projektstandards und Dokumentation. | Verständnis des Projektportfolios mit klarem Fokus auf die kommerziellen Initiativen und deren Beitrag zur Gesamt-EPD-AA-Roadmap.","Verantwortung für die Stakeholder-Beziehungen im kommerziellen Bereich, Sicherstellung der Abstimmung mit AA-Möglichkeiten, Umfang und Roadmap in Abstimmung mit dem direkten Vorgesetzten. | Anwendung strukturierter Governance auf Projektportfolios zur Sicherstellung von Transparenz und Ausrichtung an übergeordneten Geschäftszielen. | Leitung der Projektplanung, Verfolgung der Lieferungen, Förderung offener Kommunikation durch Workshops und Führung der Stakeholder hin zu datengetriebenen Entscheidungen mit Unterstützung des direkten Vorgesetzten. | Vorbereitung und Leitung von Projekt-Steuerungsausschuss- und Vorstandssitzungen. | Coaching von Stakeholdern über Funktionen hinweg, um sich sicher in einer Machine Learning- und datenorientierten Umgebung zu bewegen. | Identifikation wichtiger Stakeholder und Fachexperten zur Unterstützung und Förderung der Projektdurchführung und Lösungseinführung mit Unterstützung des direkten Vorgesetzten.",Data Scientist
358,Data Analyst/in Paid Media,Emil Frey Gruppe Schweiz,Zürich,"Regelmässige Überwachung relevanter Medienkanäle und Social Media-Plattformen | Quantitative Auswertung der Medienpräsenz (Reichweite, Kosten, CPX) | Erstellung von Dashboards, Reports und Präsentationen für interne und externe Stakeholder | Ableitung von Handlungsempfehlungen für Paid-Media- und Optimierungen in | Zusammenarbeit mit Mediaplaner oder Mediastrategen | Benchmarking der Ergebnisse und Aufbau einer Benchmark Sammlung | Unterstützung bei Kampagnen-Evaluierungen und ROI-Messungen
Monitoring, Analysen und Erfolgskontrolle | Aufbau, Pflege und Auswertungen von Tracking set-ups
Kenntnisse von Marketing Attributionsmodellen | Deutsch: in Wort und Schrift verhandlungssicher | Englisch: sehr gute Kenntnisse in Wort und Schrift | weitere Sprachen von Vorteil","Abgeschlossenes Studium im Bereich Informatik, Wirtschaftsinformatik, Data Science, Statistik oder vergleichbare Aus-/Weiterbildung | Mindestens 3-5 Jahre Berufserfahrung im Bereich Analytics, Paid Media, Website, Social Media oder vergleichbar, Hohe Zahlenaffinität | Erfahrung in Medienanalyse, Medien Tools, Social-Media-Monitoring oder Marktforschung | Sicherer Umgang mit Medienbeobachtungs- und Analysetools | Kenntnisse in Datenanalyse und Visualisierung (z. B. Excel, Power BI, Tableau, Looker Studio) | Analytisches Denkvermögen und hohe Detailgenauigkeit, sowie die Fähigkeit komplexe Daten verständlich und zielgruppenorientiert aufzubereiten | Ausgeprägte schriftliche und mündliche Kommunikationsfähigkeiten | Teamorientierte und selbstständige Arbeitsweise sowie hohes Organisationstalent | Hohe Automotive-Affinität von Vorteil | Sprachkenntnisse
Deutsch: in Wort und Schrift verhandlungssicher 
Englisch: sehr gute Kenntnisse in Wort und Schrift
weitere Sprachen von Vorteil | Deutsch: in Wort und Schrift verhandlungssicher | Englisch: sehr gute Kenntnisse in Wort und Schrift | weitere Sprachen von Vorteil",Data Scientist
359,Senior Machine Learning Engineer,RUAG AG,Bern,"Entwicklung, Training und Deployment von Machine-Learning-Modellen für Produktionsbetrieb | Aufbau und Wartung von End-to-End-ML-Pipelines (Datenvorbereitung, Feature-Engineering, Modelltraining, Monitoring, etc.) | Sicherstellung von Transparenz, Nachvollziehbarkeit und Skalierbarkeit durch Best Practices (CI/CD, MLOps, Testing)","Bachelor oder Master-Abschluss in Computer Science oder benachbartem Gebiet | Mehrjährige Berufserfahrung im Machine-Learning-/MLOps/DevOps-Umfeld | Erfahrung als Pre-Sales- oder Software Engineer von Vorteil | Starke Kenntnisse in Software-Engineering in Python, TensorFlow, PyTorch, und weiteren ML-Frameworks, sowie Docker, Kubernetes, APIs und Testing, CI/CD, Versionierung mit Git, etc. | Teamorientierte Arbeitsweise mit Schwerpunkt auf Zusammenarbeit und Anpassungsfähigkeit | Sehr gute Englisch- und/oder Deutschkenntnisse zur Zusammenarbeit mit Teammitgliedern",Machine Learning Engineer
360,Machine Learning Engineer,RUAG AG,Bern,"Entwicklung, Training und Deployment von Machine-Learning-Modellen für Produktionsbetrieb | Aufbau und Wartung von End-to-End-ML-Pipelines (Datenvorbereitung, Feature-Engineering, Modelltraining, Monitoring, etc.) | Sicherstellung von Transparenz, Nachvollziehbarkeit und Skalierbarkeit durch Best Practices (CI/CD, MLOps, Testing)","Bachelor oder Master-Abschluss in Computer Science oder benachbartem Gebiet | Starke Kenntnisse in Software-Engineering in Python, TensorFlow, PyTorch, und weiteren ML-Frameworks, sowie Docker, Kubernetes, APIs und Testing, CI/CD, Versionierung mit Git, etc.- | Erfahrung in Machine-Learning-/MLOps/DevOps-Umfeld oder als Pre-Sales- oder Software Engineer von Vorteil | Teamorientierte Arbeitsweise mit Schwerpunkt auf Zusammenarbeit und Anpassungsfähigkeit | Sehr gute Englisch- und/oder Deutschkenntnisse",Machine Learning Engineer
361,Platform Engineering Internship (80-100% - 12 months),Swissgrid AG,Bleichemattstrasse 31,"GitHub Operations (Manage hybrid setup, user & access management as well as helping other developers how to use the platform) | Data Platform Operations (Design, deploy, review, and monitor cloud infrastructure for the data platform) | Development Tools (Container based Development environments & CI/CD Pipelines)","Good practices with software engineering disciplines (e.g., CI/CD (GitHub actions), Container/Kubernetes/Docker, Infrastructure as Code (terraform), ...) | Be able to analyze, monitor, and troubleshoot cloud-based distributed systems (pref. Microsoft Azure, Databricks & Ray) | Experience with the GitHub ecosystem or similar (Repos, Actions, Packages, ...) | Proficiency in at least one modern programming language (Python, Go, C#, ...) | Knowledge of Linux systems and shell scripting | Be proficient with the English language",Machine Learning Engineer
365,"Cloud Operations Engineer (all genders), 80-100%",BSI Business Systems Integration AG,Zürich,"Mit innovativen Cloud-Lösungen in- und externe Kunden glücklich machen | Sicherstellung des robusten, effizienten SaaS Betriebs gemäss SLA | Analyse und Behebung von Störungen | Unterhalts- und Wartungsarbeiten sowie Systemsicherungsmassnahmen | Planung und Durchführung aller regulären Tagesarbeiten und operationeller Prozesse | Pflegen der Dokumentationen | 2nd-Level-Support für in- und externe Kunden und Partner","Abgeschlossene Lehre, 2-3 Jahre Erfahrung in diesem Gebiet | Breite Kenntnisse in den Bereichen Netzwerk, Security, Virtualisierung, Container (Docker/Kubernetes) | Erfahrung mit Automatisierungstools (Ansible, Terraform) und Skriptsprachen (Bash, Python) | Fundiertes Linux Knowhow (Ubuntu/Debian, RedHat/CentOS) | Neugier, effizientes Arbeiten und unternehmerisches Denken | Sehr gute Deutsch- und Englischkenntnisse",Machine Learning Engineer
367,Graduate program - Quality Assurance Engineer (m/f/d),Hapa AG,Volkestwil,"Real-world projects with impact: you will collaborate with like-minded peers and tackle challenging projects, developing cutting-edge technology solutions, learning on the job since day one | Professional development and training: you will enhance your technical and soft skills through dedicated learning & development initiatives | Mentorship by industry leaders: you will gain invaluable insights from seasoned professionals who have successfully paved their paths in the engineering landscape | Networking opportunities: you will forge lifelong connections with fellow engineers and industry experts, enabling you to establish meaningful relationships that will propel your career forward | Recognition and reward: your contribution will be recognized. Coesia Graduates Program rewards those who consistently strive for excellence.","Collaborate closely with Production, Procurement, Quality, and HSE Managers to ensure the quality and reliability of production processes, emphasizing machinery and printing machines | Ensure effective handling and resolution of non-conformities in production, including deviation opening | Monitor and analyze quality performance metrics, identifying process improvement opportunities with the team to ensure high production quality | Manage complaints if required | Work closely with Manufacturing, Engineering, Procurement, Technical Support, and Suppliers to develop and implement robust manufacturing processes and quality controls | Ensure compliance with ISO 9001 requirements within the production environment | Manage and coordinate CAPA (Corrective and Preventive Actions) processes, as well as Production Deviation management, ensuring timely resolution and continuous improvement | Coordinate with suppliers to address quality-related issues promptly and effectively | Support Factory Acceptance Testing processes and lead quality actions to ensure adherence to quality standards",Machine Learning Engineer
369,Machine Learning Engineer,Vitol SA,Geneva,Full-time,"Being an energetic and enthusiastic member of a team uniquely positioned to bring the power of data to bear on the inner workings of the energy industry | Leading design, development, and deployment of machine learning systems, bringing their technical knowledge and experience into the team, and using this to create real solutions to real problems | Collaborating with cross-functional technology teams to gather requirements and ensure the solutions align with business objectives | Helping integrate the team’s solutions (including generative AI) into existing systems and platforms to provide seamless user experiences and scale adoption | Actively participating in code reviews, experiment design and tooling decisions to help drive the team’s velocity and quality | Helping build data and machine learning expertise within the business through knowledge sharing",Machine Learning Engineer
371,Senior Data Engineer,ti&m AG,Zürich,Spannende und innovative Datenprojekte für unsere Kunden | Zusammen mit unseren Data – und Machine-Learning-Engineers entwickelst du komplexe Data-Processing-Pipelines in der Cloud oder on-Premise | Du übernimmst Verantwortung für datengetriebene Beratungsmandate | Du berätst unsere Kunden bei der Umsetzung von modernen Datenhaltunslösungen und bei der Technologiewahl | Du übernimmst inhaltliche Verantwortung für technologische Themenbereiche | Fortwährendes Lernen und stetige Weiterbildung sowie Einblicke in die verschiedenen Branchen unserer Kunden | Abwechslung und spannende Zusammenarbeit in internen Projektteams sowie vor Ort bei unseren Kunden,"Abschluss an einer (Fach-)Hochschule im Bereich Informationstechnologie, Informatik, Wirtschaftsinformatik oder einem verwandten Gebiet | Mehr als 5 Jahre nachweisbare Erfahrung auf relevanten Projekten | Sehr gute Kenntnisse in SQL und Python | Grundwissen in der Arbeit mit Infrastructure as Code (IaC) und Automatisierungstools wie Terraform, Azure ARM, Azure DevOps und GitLab CI | Fundierte Kenntnisse in relevanten Technologien wie Spark, Hive, Apache Iceberg, Airflow, MageAI, Pandas, PySpark oder ähnlichen | Praktische Erfahrung und gute Kentnisse im Aufbau von Datalakes oder Data Lakhouses | Erfahrung im Bereich der Software-Entwicklung | Praktische Erfahrung mit ETL und ELT Prozessen | Erfahrung im Umgang mit Datentechnologien von einem der grossen Cloud-Anbieter",Machine Learning Engineer
373,Senior Machine Learning Engineer - LLM & AIOps (m/w/d),Rocken®,Zürich,"Erfahrung in Entwicklung, Training und Bereitstellung von ML-Systemen in der Produktion | Kenntnisse in der Implementierung von LLM-/RAG-Systemen | Erfahrung im Kubernetes-Ökosystem (z. B. Helm, ArgoCD) | Interesse und Bereitschaft zur Arbeit mit agentenbasierten KI-Systemen | Erfahrung mit Open-Source-LLMs und Tools wie vLLM, llama.cpp oder open-webui | Verständnis oder Erfahrung mit parallelem/verteiltem Rechnen | Kenntnisse in UI-Frameworks (z. B. Streamlit, Svelte) für KI-Prototypen | Grundlegende SQL-Kenntnisse | Erfahrung mit Airflow","Mindestens 4 Jahre Erfahrung in der Entwicklung und Wartung von ML-Systemen (Promotion anrechenbar) | Sehr gute Python-Kenntnisse | Gute Kenntnisse im Umgang mit Linux | Erfahrung mit komplexen, rechnergestützten, wissenschaftlichen Modellen | Verständnis von AIOps, DevOps und den Anforderungen für produktive KI-Systeme | Sehr gute Deutschkenntnisse",Machine Learning Engineer
374,Machine Learning Research Engineer,ETH Zürich,Oerlikon,"Master’s degree or higher in Computer Science, Artificial Intelligence, or related field. | Proven experience in machine learning and neural network architectures. | Strong programming skills in Python and familiarity with PyTorch. | Experience with software development practices, including version control systems, debugging, testing, and deployment. | Excellent problem-solving abilities and strong analytical skills. | Ability to work effectively in a team as well as independently. | A stimulating academic environment at one of the world's leading technical universities | The opportunity to work with state-of-the-art supercomputing infrastructure and cutting-edge AI research | Collaboration with top researchers and engineers from ETH Zurich, EPFL, CSCS, and other Swiss institutions | Flexible working arrangements, including options for remote work | Professional development opportunities, including conference attendance and specialized training | The chance to contribute to open-source projects with global impact | Access to the broader Swiss academic ecosystem and industry partnerships | Being part of Switzerland's sovereign AI development, working on technology with national significance | CV/Resume | Cover letter explaining your interest and qualifications | Academic transcripts | Contact information for 2-3 references | Links to GitHub repositories or other examples of your programming work (if available)",no skills found on this job ad,Machine Learning Engineer
375,Data Architect,ti&m AG,Zürich,Spannende und innovative Datenprojekte für unsere Kunden | Ein breites Spektrum an Aufgaben: Zusammen mit unseren Data – und Machine-Learning-Engineers entwickelst du komplexe Data-Processing-Pipelines in der Cloud oder on-Premise | Projektverantwortung: Du übernimmst Verantwortung für datengetriebene Beratungsmandate | Kundennähe: Du berätst unsere Kunden bei der Umsetzung von modernen Datenhaltunslösungen und bei der Technologiewahl | Inhaltliche Verantwortung für technologische Themenbereiche | Fortwährendes Lernen und stetige Weiterbildung sowie Einblicke in die verschiedenen Branchen unserer Kunden | Abwechslung und spannende Zusammenarbeit in internen Projektteams sowie vor Ort bei unseren Kunden,"Abschluss an einer (Fach-)Hochschule im Bereich Informationstechnologie, Informatik, Wirtschaftsinformatik oder einem verwandten Gebiet | Mehr als 8 Jahre nachweisbare praktische Erfahrung in relevanten Projekten | Sehr gute Kenntnisse in SQL und Python | Fundierte Kenntnisse in relevanten Technologien wie Spark, Hive, Apache Iceberg, Airflow, Pandas, PySpark oder ähnlichen | Praktische Erfahrung mit ETL und ELT | Sehr gute Kenntnisse über Datenmodelle, insbesondere Data Vault | Praktische Erfahrung und sehr gute Kenntnisse mit Data Lakes und Data Lakehouses | Ein fundiertes Verständnis für Software Engineering | Sicheres Auftreten und ausgezeichnete Kommunikationsfähigkeiten | Praktische Erfahrung mit Daten-Technologien der führenden Cloud-Anbieter",Machine Learning Engineer
376,Data Architect - National Security,ti&m AG,Bern,"Spannende und innovative Datenprojekte für unsere Kunden | Ein breites Spektrum an Aufgaben: Zusammen mit unseren Data – und Machine-Learning-Engineers entwickelst du komplexe Data-Processing-Pipelines in der Cloud oder on-Premise | Projektverantwortung: Du übernimmst Verantwortung für datengetriebene Beratungsmandate | Kundennähe: Du berätst unsere Kunden bei der Umsetzung von modernen Datenhaltunslösungen und bei der Technologiewahl | Inhaltliche Verantwortung für technologische Themenbereiche | Attraktive Weiterentwicklung – fachlich wie persönlich, ganz nach deinem Stil | Fortwährendes Lernen und stetige Weiterbildung sowie Einblicke in die verschiedenen Branchen unserer Kunden | Abwechslung und spannende Zusammenarbeit in internen Projektteams sowie vor Ort bei unseren Kunden","Abschluss an einer (Fach-)Hochschule im Bereich Informationstechnologie, Informatik, Wirtschaftsinformatik oder einem verwandten Gebiet | Mehr als 8 Jahre nachweisbare praktische Erfahrung in relevanten Projekten | Fundierte Kenntnisse in relevanten Technologien wie Spark, Hive, Apache Iceberg, Airflow, Pandas, PySpark oder ähnlichen | Praktische Erfahrung mit ETL und ELT | Sehr gute Kenntnisse über Datenmodelle, insbesondere Data Vault | Praktische Erfahrung und sehr gute Kenntnisse mit Data Lakes und Data Lakehouses | Ein fundiertes Verständnis für Software Engineering | Sicheres Auftreten und ausgezeichnete Kommunikationsfähigkeiten | Militärische Karriere als höherer Unteroffizier oder Offizier von Vorteil",Machine Learning Engineer
381,Data Engineer (m/f/d),mimacom ag,Zürich,"Aufbau skalierbarer Datenpipelines (ETL/ELT, Streaming) und semantischer BI-Schichten | Entwurf und Betrieb von Lakehouse-Architekturen | Entwicklung und Pflege von Dashboards und Analyseplattformen | Sicherstellung von Sicherheit, Skalierbarkeit und Überwachung unserer Dateninfrastruktur | Zusammenarbeit mit Experten aus den Bereichen Data Science, Machine Learning und Cloud Engineering","Erfahrung auf Senior-Level im Bereich Data Engineering & BI | Fundierte Kenntnisse mit Cloud-Plattformen (Databricks, AWS, Azure) | Praktische Erfahrung in Data Warehousing (Snowflake, Redshift, BigQuery) und Big Data-Technologien (Hadoop, Spark) | Kenntnisse in Python, R, SQL | Erfahrung mit ML-Frameworks (TensorFlow, PyTorch, Scikit-learn) | Vertrautheit mit IaC-Tools (Terraform, CloudFormation) sowie SQL- & NoSQL-Datenbanken | Sprachkenntnisse (mind. C1): Deutsch und Englisch | Universitätsabschluss in Informatik, Mathematik, Statistik, Wirtschaftsinformatik oder einem verwandten Fachgebiet",Machine Learning Engineer
383,Cloud Platform Engineer (MLOps),SonarSource SA,Geneva,"Collaborate with AI researchers and engineers to bridge the gap between research and production. | Manage research-friendly cloud environments that allow easy deployment and experimentation. | Deploy, manage, and monitor LLM/ML models in both cloud and on-premise environments, ensuring smooth integration into our research and production pipelines. | Support engineers in integrating ML models into production, ensuring a smooth handoff from research to product teams. | Automate ML workflows with CI/CD pipelines for model deployment and continuous integration. | Design and maintain flexible ML workflows to support rapid experimentation. | Enable fast iteration by setting up tools for model tracking, logging, and comparison (e.g., MLflow, DVC, Weights & Biases). | Optimize model inference for speed, efficiency, and scalability while balancing research flexibility. | Ensure AI models and experiments are reproducible by structuring model storage, versioning, and benchmarking practices.","Technical background with a university degree in Computer Science, software engineering or a related field. | Strong programming skills in Python. Proficiency in other languages such as Java is a plus. | Proficiency with DevOps/MLOps best practices, including CI/CD, version control (Git), docker and IaC. | Proficiency with AWS infrastructure, including EC2, S3, SageMaker and Bedrock. | Experience deploying ML models and LLMs in cloud environments and local environments. | Familiarity with distributed model training and model optimization. | Ability to build effective ML pipelines for research and development. | Experience with ML model lifecycle tools (e.g., MLflow, DVC, Weights & Biases). | Excellent problem-solving skills, with the ability to troubleshoot performance bottlenecks in ML pipelines. | Fluent in English, with the ability to communicate complex technical topics effectively.",Machine Learning Engineer
384,Bioinformatics Engineer (12 Month Contract),Sophia Genetics SA,Rolle,"Koordination und Leitung der Aktivitäten der funktionsübergreifenden Pipeline-Integrations-Taskforce während jedes Release-Zyklus. Dies umfasst: | Durchführung der abschließenden Überprüfung der Data-Science-Entwicklungen | Genehmigung von Merge Requests und Stabilisierung von Branches | Testen des Pakets, das alle in SOPHiA DDM verfügbaren Pipelines enthält",Als primärer Ansprechpartner für die Data-Science-Abteilung fungieren und die Koordination sowie Kommunikation mit anderen am Release-Prozess beteiligten Abteilungen managen.,Machine Learning Engineer
386,CI/CD Engineer & Consultant,Digital Architects Zurich GmbH,Zurich,"Die Arbeit mit Kunden in Projekten, die Sie von Anfang bis Ende mitgestalten können | Ein abwechslungsreiches Tätigkeitsfeld als Spezialist mit Verantwortung für Beratung, Design und Entwicklung von Continuous Integration / Continuous Delivery (CI/CD) für kritische Anwendungen | Entwicklung von Lösungen mit der neuesten CI/CD-Technologie (Open Source oder kommerzielle Software) sowie Automatisierung, kontinuierliche Verifizierung mit maschinellem Lernen und Monitoring/Observability, in der Cloud und vor Ort | Zusammenarbeit und Unterstützung von Anwendungsentwicklern und -teams für die effiziente Einführung und Nutzung von CI/CD | Selbstständige Arbeit, auch Teilzeit (80-100%) | Ausbildung, Schulung und Möglichkeiten zur Mitgestaltung | Eintritt in ein hilfsbereites und kollegiales Umfeld","Ein Entwicklung- und Ingenieursgeist sowie die Fähigkeit, Wissen aus verschiedenen Bereichen anzuwenden, um die komplexen Probleme des zuverlässigen Betriebs von großangelegten Anwendungen zu lösen | Freude an technischen Details und Kundenkontakt | Erfahrung mit CI und/oder CD und verwandten Technologien: Jenkins, Harness, Gitlab, ArgoCD, Tekton, Terraform, … | Kenntnisse in Software Engineering (Java, JavaScript) und Skripting (Shell, Python) | Erfahrung mit Linux und Docker/Kubernetes als Benutzer, Administrator oder Ingenieur | Idealerweise Erfahrung mit Agile, DevOps, Site Reliability Engineering oder in einem ähnlichen Umfeld – was Sie nicht haben, bringen wir Ihnen bei! | Gute Deutsch- und Englischkenntnisse | Flexibilität für Einsätze bei verschiedenen Kunden in Zürich, Bern oder Basel | Teamgeist, Initiative, Verantwortung, kreatives und analytisches Denken | Wir setzen voraus, dass Sie bereits eine Aufenthalts- und Arbeitsgenehmigung für die Schweiz besitzen",Machine Learning Engineer
387,Observability & AIOps Engineer/Consultant,Digital Architects Zurich GmbH,Zurich,"Arbeiten mit Kunden in Projekten, die Sie von Anfang bis Ende mitgestalten können | Vielfältiges Tätigkeitsfeld als Spezialist mit Verantwortung für Beratung, Design und Entwicklung von Observability & AIOps für kritische Anwendungen | Entwicklung von Lösungen mit der neuesten und führenden Observability & AIOps-Technologie (Open Source oder kommerzielle Software), Nutzung von maschinellem Lernen für unternehmensgerechte Automatisierung, in der Cloud und On-Premises | Zusammenarbeit und Unterstützung von Anwendungsentwicklern und -teams für die effiziente Einführung und Nutzung von Observability, Monitoring & AIOps | Selbstständige Arbeit, auch Teilzeit (80-100%) | Ausbildung, Schulung und Möglichkeiten zur Mitgestaltung | Teil eines hilfsbereiten und kollegialen Umfelds werden","Ein Entwicklungs- und Ingenieursgeist sowie die Fähigkeit, Wissen aus verschiedenen Bereichen anzuwenden, um die komplexen Probleme des zuverlässigen Betriebs von großangelegten Anwendungen zu lösen | Freude an technischen Details und Kundenkontakt | Ingenieur- oder Verwaltungserfahrung mit Monitoring-, APM-, Observability- oder AIOps-Lösungen: Splunk, SignalFX, Dynatrace, New Relic, Elastic, Datadog, IBM Instana, Cisco AppDynamics, … | Kenntnisse in Softwareentwicklung (Java, JavaScript) und Skripting (Shell, Python) | Erfahrung mit Linux und Docker/Kubernetes als Benutzer, Administrator oder Ingenieur | Idealerweise Erfahrung mit Agile, DevOps, Site Reliability Engineering oder in einem ähnlichen Umfeld – was Sie nicht haben, bringen wir Ihnen bei! | Gute Deutsch- und Englischkenntnisse | Flexibilität für Einsätze bei verschiedenen Kunden in Zürich, Bern oder Basel | Teamgeist, Initiative, Verantwortung, kreatives und analytisches Denken | Wir setzen voraus, dass Sie bereits eine Aufenthalts- und Arbeitsgenehmigung für die Schweiz besitzen",Machine Learning Engineer
388,Senior AI Engineer,Nexthink SA,Prilly,Full-time,"Implement new AI features with high-quality coding standards and automated test coverage | Solve the engineering challenges behind data collection, retrieval, evaluation and inference at scale | Build and maintain CI/CD pipelines for AI components, ensuring safe, repeatable deployments | Instrument robust online/offline evaluation metrics and dashboards to monitor quality in production | Proactively propose new product capabilities or improvements based on user data and technology advances | Stay current with the rapidly evolving AI engineering ecosystem and share knowledge with the Nexthink community | Mentor junior engineers in best practices for shipping and operating AI features in production | Communicate effectively with (non-technical) stakeholders such as product managers and UX designers",Machine Learning Engineer
391,Senior Data Engineer mit Flair für AI,ti&m AG,Bern,"Entwicklung moderner Datenpipelines in der Cloud (Azure) oder on-prem | Aktive Mitarbeit an Projekten, die Daten und KI verbinden: von klassischem ML bis hin zu GenAI (RAG, Agentic AI, MCP) | Einsatz eines breiten Tech-Stacks: Python (PyTorch, scikit-learn, FastAPI, LangChain) ergänzt durch Tools wie Spark, Pandas und Airflow | Arbeit mit MLOps-Technologien wie Docker, Kubernetes, Terraform, MLflow oder Azure ML | Kundenkontakt von Workshops bis zur Umsetzung skalierbarer Lösungen | Abwechslungsreicher Alltag zwischen Datenanalyse, Architektur-Design und Implementierung | Zusammenarbeit in einem motivierten, offenen und unkomplizierten Team – professionell und unverkrampft | Raum für Weiterbildung sowie die Möglichkeit, Neues auszuprobieren und voneinander zu lernen","Studium (FH/Uni) in Informatik oder vergleichbare Weiterbildung | Mehrjährige Praxis in der Entwicklung von Datenpipelines | Sehr gute Kenntnisse in Python und im Umgang mit Datenframeworks (z. B. Pandas, Spark) | Erfahrung mit Cloud-Services, vorzugsweise Azure | Sicherer Umgang mit SQL-Datenbanken | Erste Erfahrungen mit Machine Learning oder GenAI (z. B. PyTorch, scikit-learn, LangChain) | Kenntnisse im Bereich MLOps (Docker, Kubernetes, Terraform, MLflow, Azure ML) sind hilfreich | Erfahrung mit Workflow-Tools wie Airflow oder Hive ist ein Vorteil | Vertrautheit mit CI/CD-Pipelines und GitOps rundet das Profil ab",Machine Learning Engineer
395,Machine Learning Developer (EP-CMG-OS-2025-154-GRAP),CERN European Organization for Nuclear Research,Geneva,"Entwicklung eines innovativen selbstüberwachten, physik-informierten Machine Learning-Ansatzes für eine schnelle und robuste Interpretation von Kollisionsereignissen (z.B. Klassifikation, Regression, Anomalieerkennung) im CMS Phase-2 L1 Trigger. | Reduzierung der L1-Scouting-Datensatzgröße durch intelligente Datenkompression bei gleichzeitiger Erhaltung der physikalischen Aussagekraft. | Statistische Interpretation von Ausreißer-Kollisionsereignissen, die 2025 vom CMS mit einem Anomalieerkennungs-Trigger basierend auf Autoencodern gesammelt werden. | Effektive Zusammenarbeit im Team, einschließlich Kollegen an den CERN-Kooperationsinstituten. | Präsentation der Arbeit auf Konferenzen/Workshops am CERN und externen Veranstaltungsorten. | einen Masterabschluss mit 2 bis 6 Jahren Berufserfahrung nach dem Abschluss; | oder eine Promotion mit nicht mehr als 3 Jahren Berufserfahrung nach dem Abschluss. | Bereitschaftsdienst, wenn von der Organisation benötigt. | Arbeit nachts, an Sonntagen und offiziellen Feiertagen, wenn von der Organisation benötigt.","Fortgeschrittene Kenntnisse in Machine Learning-Algorithmen (boosted decision trees, neuronale Netze) einschließlich Fast Machine Learning; | Kenntnisse und Anwendung von physikalischen Analysemethoden; | Trigger- und Datenerfassungssysteme, deren Hardware und zugehörige Werkzeuge; | Software-Entwicklungsplattformen (z.B. github, gitlab) und Continuous Integration; | Grundkenntnisse und Anwendung der FPGA-Programmierung einschließlich Hardware Description Languages und High Level Synthesis; | Gesprochene und schriftliche Englischkenntnisse mit der Bereitschaft, Französisch zu lernen. | Ein monatliches Stipendium zwischen 6287 und 6911 Schweizer Franken pro Monat (netto). | Abdeckung durch das umfassende Gesundheitssystem des CERN (für Sie, Ihren Ehepartner und Ihre Kinder) sowie Mitgliedschaft im CERN Altersvorsorgefonds. | Je nach individueller Situation: Installationszuschuss; Familien-, Kinder- und Säuglingszulagen; Erstattung der Reisekosten zu Beginn und Ende des Vertrags. | 30 Tage bezahlter Urlaub pro Jahr. | On-the-Job- und formale Schulungen am CERN sowie interne Sprachkurse für Englisch und/oder Französisch.",Machine Learning Engineer
397,"Student Internship: ML Engineer - Data, Machine Learning & AI (m/f/d)",Endress+Hauser,Reinach BL,"Mit Produkt- und Engineering-Teams zusammenarbeiten, um Datenanforderungen zu verstehen und zu KI-gesteuerten Funktionen beizutragen | Bei der Gestaltung und Entwicklung von Modellen des maschinellen Lernens für vielfältige Anwendungen in der Prozessautomatisierung unterstützen | Daten sammeln, vorverarbeiten und analysieren, um Modelle zu trainieren und zu bewerten | Zur Entwicklung skalierbarer Datenpipelines und APIs für KI-Anwendungen beitragen | An Code-Reviews, agilen Entwicklungsprozessen und Teamdiskussionen teilnehmen | Mit modernen KI-Frameworks und Bibliotheken wie TensorFlow, PyTorch oder LangGraph experimentieren | Ihre Arbeit dokumentieren und Erkenntnisse mit dem Team teilen, um Lernen und Innovation zu fördern","Studieren derzeit einen Bachelor- oder Masterstudiengang in Informatik, Data Science, KI oder einem verwandten Bereich | Haben großes Interesse an angewandtem maschinellen Lernen, Datenengineering und KI-Technologien wie LLMs und autonomen Agenten | Verfügen über grundlegende Programmierkenntnisse in Python; Erfahrung mit Bibliotheken wie NumPy, pandas oder scikit-learn ist von Vorteil | Verstehen grundlegende ML-Konzepte wie überwachtes Lernen, Modellevaluation und Feature Engineering | Haben erste Erfahrungen mit Cloud-Plattformen (z. B. Azure, AWS, GCP) oder Versionskontrollsystemen (z. B. Git) | Kommunizieren gut auf Englisch; Deutschkenntnisse sind von Vorteil | Sind neugierig, proaktiv und lernbereit in einem kollaborativen Umfeld",Machine Learning Engineer
398,Working Student - Reinforced Learning Environments (40% FTE+),Daedalean AG,Zürich,"Forschung und Entwicklung von Verstärkungslern-Umgebungen für Missionsplanung und Optimierung. | Implementierung von Verstärkungslern-Algorithmen: Anwendung und Test von Algorithmen zur Verbesserung der Entscheidungsfindung in simulierten Umgebungen. | Durchführung von Experimenten und Analyse der Ergebnisse: Durchführung von Simulationen, Datensammlung und Bewertung der Wirksamkeit verschiedener Ansätze. | Dokumentation und Weitergabe der Ergebnisse: Erstellung klarer Dokumentationen und Berichte über deine Arbeit und Ergebnisse.","Erfahrung mit Python, C++ oder MATLAB ist von Vorteil. | Interesse an KI und maschinellem Lernen: Fortgeschrittene Kenntnisse oder Kurse in Verstärkungslernen, maschinellem Lernen oder verwandten Bereichen. | Interesse an Computerspielen. | Studium der Robotik, Informatik oder eines verwandten technischen Fachgebiets.",Machine Learning Engineer
399,Senior AI Systems Engineer (m/w/d),Rocken®,Zürich,"Entwicklung von KI- und Machine-Learning-Anwendungen sowie Aufbau von RAG-Systemen und agentenbasierten KI-Workflows | Optimierung der Bereitstellung von LLMs und Skalierung von Training und Inferenz auf GPU-Clustern mit Kubernetes und AIOps-Tools | Überführung von Prototypen aus Forschung und Entwicklung in stabile Produktionssysteme | Erforschung, Evaluation und Umsetzung neuer Methoden und Technologien zur Weiterentwicklung der KI- und ML-Landschaft bei Viseca | Verbesserung interner AIOps-Praktiken und Workflows | Betreuung und Weiterentwicklung der internen KI-Infrastrukturen und Tools","Mindestens 4 Jahre Erfahrung in der Entwicklung und Wartung von ML-Systemen (Promotion anrechenbar) | Erfahrung mit komplexen, rechnergestützten, wissenschaftlichen Modellen | Verständnis von AIOps, DevOps und den Anforderungen für produktive KI-Systeme | Sehr gute Python-Kenntnisse | Gute Kenntnisse im Umgang mit Linux | Sehr gute Deutschkenntnisse",Machine Learning Engineer
403,AI/ML Engineer (IT-CA-OSI-2025-191-GRAE),CERN European Organization for Nuclear Research,Geneva,"Expertise im maschinellen Lernen: Erfahrung in der Bewertung von Modellen zur Textextraktion, Klassifikation und Informationsabruf sowie praktische Kenntnisse im Einsatz, der Integration und Optimierung von Open-Source-LLMs. | Softwareentwicklung: starke Programmierkenntnisse in Python und Erfahrung mit Open-Source-ML/AI-Agent-Frameworks. | Datenverarbeitung & Pipelines: Fähigkeit, skalierbare Datenpipelines zu entwerfen und mit heterogenen Datensätzen zu arbeiten. | Infrastruktur & Bereitstellung: Vertrautheit mit containerisierten Umgebungen (Docker, Kubernetes/OpenShift) und Bereitstellungsautomatisierung (Helm-Charts). | Kommunikations- und Kollaborationsfähigkeiten: Fähigkeit, klar zu kommunizieren, in multidisziplinären Teams zu arbeiten und zu Open-Source-Projekten beizutragen. | Gesprochene und geschriebene Englischkenntnisse mit der Bereitschaft, Französisch zu lernen. | Ein monatliches Stipendium zwischen 5196 und 5716 Schweizer Franken (netto). | Absicherung durch das umfassende Gesundheitssystem von CERN (für Sie, Ihren Ehepartner und Ihre Kinder) sowie Mitgliedschaft im CERN-Altersvorsorgefonds. | Je nach individueller Situation: Umzugskostenbeihilfe; Familien-, Kinder- und Säuglingszulagen; Erstattung der Reisekosten zu Beginn und Ende des Vertrags. | 30 Tage bezahlter Urlaub pro Jahr. | On-the-Job- und formale Schulungen bei CERN sowie interne Sprachkurse für Englisch und/oder Französisch.","Sie sind Staatsangehöriger eines CERN-Mitglieds- oder assoziierten Mitgliedsstaates
. | Bis zum Bewerbungsschluss verfügen Sie über maximal zwei Jahre Berufserfahrung seit dem Abschluss in Softwareentwicklung und Datenwissenschaft (oder einem verwandten Bereich) und Ihre höchste Ausbildung ist entweder ein Bachelor- oder Masterabschluss. | Sie hatten noch nie einen CERN-Stipendiaten- oder Absolventenvertrag. | Bewerber ohne Universitätsabschluss sind nicht zugelassen. | Bewerber mit einer Promotion sind nicht zugelassen.",Machine Learning Engineer
408,Security Engineer,Zühlke Engineering AG,Schlieren,"Sie übernehmen Verantwortung in Kundenprojekten in den unterschiedlichsten Branchen (Definition der methodischen Vorgehensweise, Entwicklung von Use Cases mit Kunden, Beratung der Kunden zu technischen Themen sowie Präsentation und Erklärung der Ergebnisse). | Dank Ihrer Leidenschaft begeistern Sie unsere Kunden für das Thema Cybersicherheit. | Sie entwickeln Machine-Learning-Lösungen: Datenaufbereitung, Modellierung, Methodenauswahl, Bewertung, Implementierung. | Sie bewerten die technische und wirtschaftliche Machbarkeit von Cybersicherheitslösungen. | Sie tragen zur Weiterentwicklung unserer Cybersecurity-Praxis bei und unterstützen aktiv die Akquise von Kundenprojekten. | Sie verfügen über einen Bachelor- oder Masterabschluss (FH, ETH, Uni) in Informatik oder eine vergleichbare Ausbildung (z. B. Mathematik). | Sie haben Erfahrung in ähnlichen Rollen in mittelgroßen bis großen Lösungsprojekten oder bereits durch Ihre Begeisterung für Cybersicherheit Erfahrung gesammelt. | Ihre Leidenschaft für Cybersicherheit zeichnet Sie aus | Sie finden ein gutes Gleichgewicht zwischen Effizienz und Qualität in Projekten. | Dank Ihrer offenen und kommunikativen Persönlichkeit fühlen Sie sich in interdisziplinären Teams wohl und können kundenorientiert arbeiten – von der Idee bis zur erfolgreichen Umsetzung einer Lösung. | Deutschkenntnisse sind erforderlich. Sehr gute Englischkenntnisse runden Ihr Profil ab. | Work-Life-Blending: Wir bieten einen sicheren und gesunden Arbeitsplatz mit flexiblen Arbeitszeiten und der Möglichkeit, von zu Hause aus zu arbeiten. | Gewinnbeteiligung: Zusätzlich zu Ihrem Jahresgehalt können Sie eine Gewinnbeteiligung erhalten, die am Erfolg des Unternehmens im Vorjahr bemessen wird. | Globale und vielfältige Zühlke-Community: Erleben Sie, wie Kollegen aus all unseren 16 Büros weltweit zusammenkommen, um eine einzigartige, positive und inklusive Arbeitskultur zu schaffen, voneinander bei jährlichen Teamcamps zu lernen und Jahresendfeiern sowie andere lokale Festlichkeiten zu feiern. | Engagement für Entwicklung: Wir engagieren uns für das Wachstum unserer Mitarbeiter und investieren in Ihre Entwicklung. Wir befähigen Sie, die Fähigkeiten aufzubauen, die Sie benötigen, um heute und in Zukunft sowohl persönlich als auch für unsere Kunden einen positiven Einfluss zu haben.",no skills found on this job ad,Machine Learning Engineer
